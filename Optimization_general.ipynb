{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import mixture\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import LocallyLinearEmbedding, trustworthiness\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csgraph, csc_matrix\n",
    "import scipy.sparse.linalg as LA\n",
    "import collections\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import scipy\n",
    "\n",
    "def visualize_4d(frame, hot=True):\n",
    "  fig = plt.figure(figsize=(7, 7))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "  x = np.array(frame.iloc[:,0])\n",
    "  if len(frame.columns) > 1:\n",
    "    y = np.array(frame.iloc[:,1])\n",
    "  if len(frame.columns) > 2:\n",
    "    z = np.array(frame.iloc[:,2])\n",
    "  if len(frame.columns) == 1:\n",
    "    img = ax.scatter(x, x, s=2)\n",
    "  if len(frame.columns) == 2:\n",
    "    img = ax.scatter(x, y, s=2)\n",
    "  elif len(frame.columns) == 3:\n",
    "    img = ax.scatter(x, y, z, s=2)\n",
    "  else:\n",
    "    c = np.array(frame.iloc[:,3])\n",
    "    if hot:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap=plt.hot(), s=2)\n",
    "    else:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap='viridis', s=2)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "                  0             1             2\ncount  29678.000000  29678.000000  29678.000000\nmean     419.808233    -69.027823     31.336202\nstd      255.848084     62.353086     67.380433\nmin      -29.291716   -205.376219   -101.377696\n25%      195.227485   -112.720350    -25.854263\n50%      443.645602    -65.691209     21.230403\n75%      644.640312    -23.550395     87.041762\nmax      792.444881     69.779176    156.502445",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>29678.000000</td>\n      <td>29678.000000</td>\n      <td>29678.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>419.808233</td>\n      <td>-69.027823</td>\n      <td>31.336202</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>255.848084</td>\n      <td>62.353086</td>\n      <td>67.380433</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-29.291716</td>\n      <td>-205.376219</td>\n      <td>-101.377696</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>195.227485</td>\n      <td>-112.720350</td>\n      <td>-25.854263</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>443.645602</td>\n      <td>-65.691209</td>\n      <td>21.230403</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>644.640312</td>\n      <td>-23.550395</td>\n      <td>87.041762</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>792.444881</td>\n      <td>69.779176</td>\n      <td>156.502445</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "file = open('./R31.txt','r')\n",
    "d, n, m, k, p = list(file.readline().split())\n",
    "d, n, p, k = map(int, [d, n, p, k])\n",
    "k_list = list(map(int, file.readline().split()))\n",
    "ar = []\n",
    "for i in range(n):\n",
    "  ar.append(list(map(float, file.readline().split())))\n",
    "df = pd.DataFrame(ar)\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 4\n",
      "100.0\n",
      "outlier count: 0\n",
      "manifold count: 3\n",
      "50.0\n",
      "outlier count: 0\n",
      "manifold count: 8\n",
      "25.0\n",
      "outlier count: 0\n",
      "manifold count: 10\n",
      "12.5\n",
      "outlier count: 0\n",
      "manifold count: 11\n",
      "6.25\n",
      "outlier count: 1\n",
      "manifold count: 15\n",
      "9.375\n",
      "outlier count: 0\n",
      "manifold count: 11\n",
      "7.8125\n",
      "outlier count: 0\n",
      "manifold count: 14\n",
      "7.03125\n",
      "outlier count: 0\n",
      "manifold count: 15\n",
      "6.640625\n",
      "outlier count: 1\n",
      "manifold count: 15\n",
      "6.8359375\n",
      "outlier count: 0\n",
      "manifold count: 15\n",
      "6.73828125\n",
      "outlier count: 0\n",
      "manifold count: 15\n",
      "6.689453125\n",
      "outlier count: 0\n",
      "manifold count: 15\n",
      "6.6650390625\n",
      "outlier count: 1\n",
      "manifold count: 15\n",
      "6.67724609375\n",
      "outlier count: 0\n",
      "manifold count: 15\n",
      "6.671142578125\n",
      "outlier count: 0\n",
      "manifold count: 15\n"
     ]
    }
   ],
   "source": [
    "def find_best_eps(min_sample):\n",
    "  print(f\"samples: {min_sample}\")\n",
    "  tmp = df[[i for i in range(d)]].copy()\n",
    "  l, r = 0, 200\n",
    "  while (r - l) > 0.01:\n",
    "    mid = (r + l) / 2\n",
    "    print(mid)\n",
    "    model_name = 'dbscan'\n",
    "    model = DBSCAN(eps=mid, min_samples=min_sample)\n",
    "    model.fit(tmp[[i for i in range(d)]])\n",
    "    tmp['subset'] = model.labels_\n",
    "    print(f\"outlier count: {len(tmp[tmp['subset'] == -1])}\")\n",
    "    print(f\"manifold count: {tmp['subset'].max() + 1}\")\n",
    "    if len(tmp[tmp['subset'] == -1]) > p:\n",
    "      l = mid\n",
    "    else:\n",
    "      r = mid\n",
    "  return r\n",
    "\n",
    "# Finding subsets\n",
    "samples = 4\n",
    "best_eps = find_best_eps(samples)\n",
    "#best_eps = 82.03125\n",
    "model = DBSCAN(eps=best_eps, min_samples=2)\n",
    "model.fit(df[[i for i in range(d)]])\n",
    "df['manifold'] = model.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Counter({1: 1804})\n",
      "Counter({1: 1804})\n",
      "1\n",
      "Counter({1: 1804})\n",
      "Counter({1: 1804})\n",
      "2\n",
      "Counter({1: 1871})\n",
      "Counter({1: 1871})\n",
      "3\n",
      "Counter({1: 1893})\n",
      "Counter({1: 1893})\n",
      "4\n",
      "Counter({1: 939})\n",
      "Counter({1: 939})\n",
      "5\n",
      "Counter({1: 1893})\n",
      "Counter({1: 1893})\n",
      "6\n",
      "Counter({1: 945})\n",
      "Counter({1: 945})\n",
      "7\n",
      "Counter({1: 1828})\n",
      "Counter({1: 1828})\n",
      "8\n",
      "Counter({1: 1844})\n",
      "Counter({1: 1844})\n",
      "9\n",
      "Counter({1: 1828})\n",
      "Counter({1: 1828})\n",
      "10\n",
      "Counter({2: 1539, 1: 306})\n",
      "Counter({2: 1799, 1: 46})\n",
      "11\n",
      "Counter({1: 1889})\n",
      "Counter({1: 1889})\n",
      "12\n",
      "Counter({1: 1889})\n",
      "Counter({1: 1889})\n",
      "13\n",
      "Counter({1: 3762})\n",
      "Counter({1: 3762})\n",
      "14\n",
      "Counter({1: 3644})\n",
      "Counter({1: 3644})\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def get_local_intrinsic_dimension(data, n_neighbors=5):\n",
    "  X = np.array(data)\n",
    "  M = np.matrix(X)\n",
    "  L = n_neighbors\n",
    "  if not isinstance(L, (int, np.integer))  or L<0:\n",
    "    return 'n_neighbors must be a positive integer!'\n",
    "  neigh = NearestNeighbors(n_neighbors=L)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors()\n",
    "  mean = [np.mean([M[indices[i][j]] for j in range(L)],axis=0) for i in range(len(X))]\n",
    "  # Calculating the local covariance matrix for each point\n",
    "  C = [1/L * sum([np.dot( (M[indices[i][j],:]-mean[i]).transpose() , (M[indices[i][j],:]-mean[i]) ) for j in range(L)]) for i in range(len(X))]\n",
    "\n",
    "  # Intrinsic Dimension Estimation\n",
    "  THRESHOLD = 0.05\n",
    "  intrinsic_dimension = [0] * len(X)\n",
    "\n",
    "  E = [sorted(scipy.linalg.eigh(C[i])[0], reverse=True) for i in range(len(X))]\n",
    "  for i in range(len(X)):\n",
    "    eigen_list = E[i]\n",
    "    d = len(eigen_list)\n",
    "    first_eigenvalue= eigen_list[0]\n",
    "    for j in range(1,d):\n",
    "      if eigen_list[j]/first_eigenvalue < THRESHOLD:\n",
    "        intrinsic_dimension[i]=j\n",
    "        break\n",
    "    if intrinsic_dimension[i]==0:\n",
    "      intrinsic_dimension[i]=d\n",
    "  return np.array(intrinsic_dimension)\n",
    "\n",
    "def get_dim(X, threshold=0.95, max_d=15, print_scores=False):\n",
    "  for td in range(1, max_d):\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=90, max_iter=1000).fit_transform(X),\n",
    "                       columns=[i for i in range(td)])\n",
    "    score = trustworthiness(X, res, n_neighbors=100)\n",
    "    if print_scores:\n",
    "      print(f'dim score {td}: {score}')\n",
    "    if score >= threshold:\n",
    "      return td\n",
    "  return max_d\n",
    "\n",
    "# Assuming data is consisted of sub-manifolds with DIFFERENT dimensions OR is just consisted of one manifold\n",
    "def is_manifold(data, n_neighbors=5, error=0.05, print_accuracy=False):\n",
    "  ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  total = len(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  print(counter)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  accuracy = counter[dimension]/total\n",
    "  if accuracy > 1 - error:\n",
    "    if print_accuracy:\n",
    "     print(f'Accuracy: {accuracy}. Data resides on a {dimension}-dimensional manifold!')\n",
    "    return True, accuracy, dimension\n",
    "  if print_accuracy:\n",
    "    print(f'Accuracy: {accuracy} -> Inconclusive!')\n",
    "  return False, accuracy, dimension\n",
    "\n",
    "multi = None # subsets containing multiple manifolds\n",
    "if multi is None:\n",
    "  multi = []\n",
    "  for i in range(int(df['manifold'].max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[i for i in range(d)]]\n",
    "    dim = get_dim(X)  # could be replaced with d when d is small\n",
    "    b0, a0, d0 = is_manifold(X, n_neighbors=dim * 2)\n",
    "    b1, a1, d1 = is_manifold(X, n_neighbors=dim * 3)\n",
    "    if not b0 and not b1:\n",
    "      multi.append(i)\n",
    "      td = 3\n",
    "      res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=20, max_iter=10000).fit_transform(X), columns=[i for i in range(td)])\n",
    "      visualize_4d(res)\n",
    "      visualize_4d(X)\n",
    "\n",
    "print(multi)\n",
    "# TODO doesn't work very well maybe add dimension dfs?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "class ComponentScan:\n",
    "\n",
    "  def __init__(self, n_neighbor=10, step=20, max_rep=10):\n",
    "    self.neighbors = None\n",
    "    self.points = None\n",
    "    self.n_neighbor = n_neighbor\n",
    "    self.step = step\n",
    "    self.components_ = None\n",
    "    self.max_rep = max_rep\n",
    "\n",
    "  def fit(self, X):\n",
    "    self.neighbors = []\n",
    "    for i in range(self.max_rep):\n",
    "      nbrs = NearestNeighbors(n_neighbors=self.n_neighbor + i * self.step, algorithm='brute').fit(X)\n",
    "      self.neighbors.append(nbrs.kneighbors(X)[1])\n",
    "    self.points = X.to_numpy()\n",
    "    self.components_ = np.full((len(X)), -1)\n",
    "    return self\n",
    "\n",
    "  def predict(self):\n",
    "    cnt = 0\n",
    "    ind = 0\n",
    "    c = -1\n",
    "    rep = 0\n",
    "    while True:\n",
    "      while ind < len(self.points):\n",
    "        if self.components_[ind] == -1:\n",
    "          break\n",
    "        ind += 1\n",
    "      if ind == len(self.points):\n",
    "        break\n",
    "      stack = [ind]\n",
    "      combo = []\n",
    "      cnt = 0\n",
    "      c += 1\n",
    "      while len(stack) > 0:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "          print(f'{cnt} - {len(stack)}')\n",
    "        v = stack.pop()\n",
    "        self.components_[v] = c\n",
    "        for u in self.neighbors[rep][v]:\n",
    "          if self.components_[u] == -1:\n",
    "            stack.append(u)\n",
    "            combo.append(u)\n",
    "            self.components_[u] = c\n",
    "      if len(combo) < 100:\n",
    "        rep += 1\n",
    "        if rep == self.max_rep:\n",
    "          rep = 0\n",
    "        for c in combo:\n",
    "          self.components_[c] = -1\n",
    "      else:\n",
    "        rep = 0\n",
    "    return c + 1\n",
    "\n",
    "sp = df.copy()\n",
    "for subset in multi:\n",
    "  print(f'processing subset {subset}')\n",
    "  tmp = df[df['manifold'] == subset][[i for i in range(d)]]\n",
    "  td = 3\n",
    "  print(f'dim: {td}')\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=20,\n",
    "    max_iter=1000\n",
    "  ).fit_transform(\n",
    "    tmp\n",
    "  ), columns=[i for i in range(td)])\n",
    "  # visualize_4d(res)\n",
    "  print(f'LLE done')\n",
    "  compo = ComponentScan(n_neighbor=40, step=100).fit(res)\n",
    "  k = compo.predict()\n",
    "  print(f'manifold count: {k}')\n",
    "  if k > 10:\n",
    "    continue\n",
    "  sp.loc[sp['manifold'] == subset, 'sub1'] = compo.components_\n",
    "  print(sp.loc[sp['manifold'] == subset, 'sub1'].value_counts())\n",
    "  visualize_4d(\n",
    "    pd.DataFrame(\n",
    "      PCA(n_components=3).fit_transform(tmp),\n",
    "      columns=[j for j in range(3)]\n",
    "    ),\n",
    "    hot=False\n",
    "  )\n",
    "if len(multi) > 0:\n",
    "  sp['manifold'] = sp.manifold.astype(str) + '-' + sp.sub1.astype(str)\n",
    "  sp = sp.drop(['sub1'], axis=1)\n",
    "  sp['manifold'] = LabelEncoder().fit_transform(sp['manifold'])\n",
    "  sp['manifold'] -= 1\n",
    "  sp['manifold'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000 - 805\n",
      "1\n",
      "1000 - 805\n",
      "2\n",
      "1000 - 40\n",
      "3\n",
      "1000 - 433\n",
      "4\n",
      "5\n",
      "1000 - 489\n",
      "6\n",
      "7\n",
      "1000 - 829\n",
      "8\n",
      "9\n",
      "1000 - 829\n",
      "10\n",
      "1000 - 846\n",
      "11\n",
      "1000 - 104\n",
      "12\n",
      "1000 - 890\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# Custom cluster for manifold\n",
    "final_k_list = []\n",
    "cluster_type = []\n",
    "for i in range(int(sp.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  X = sp[sp['manifold'] == i][[j for j in range(d)]]\n",
    "  td = max(get_dim(X, max_d=7), 3)\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=50,\n",
    "    max_iter=1000\n",
    "  ).fit_transform(\n",
    "    X\n",
    "  ), columns=[i for i in range(td)])\n",
    "  k = ComponentScan(n_neighbor=40, step=30).fit(res).predict()\n",
    "  if k < 10:\n",
    "    cluster_type.append('custom')\n",
    "  else:\n",
    "    cluster_type.append('HS')\n",
    "  final_k_list.append(k if k < 10 else 1)\n",
    "xsum = 0\n",
    "for c in final_k_list:\n",
    "  xsum += c\n",
    "print(xsum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def most_common_dimension(data, n_neighbors=5):\n",
    "  ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  total = len(ID)\n",
    "  # n_manifolds = max(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  return dimension,counter[dimension]/total\n",
    "\n",
    "def estimate_intrinsic_dimension(data,n_neighbors=5, method='most_common'):\n",
    "  res = 0\n",
    "  if method=='most_common':\n",
    "    return most_common_dimension(data,n_neighbors)[0]\n",
    "  if method=='average':\n",
    "    return np.around(np.mean(get_local_intrinsic_dimension(data),axis=0),0).astype(int)\n",
    "\n",
    "plt.close('all')\n",
    "D = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  X = df[df['manifold'] == i][[j for j in range(d)]]\n",
    "  dim1 = get_dim(X, max_d=6, print_scores=True)\n",
    "  if dim1 < 6:\n",
    "    D.append(dim1)\n",
    "  else:\n",
    "    D.append(estimate_intrinsic_dimension(X, n_neighbors=2 * d))\n",
    "  print(D[-1])\n",
    "print(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Joining the cluster labeling\n",
    "def get_cluster(X, num_cluster, cluster_type):\n",
    "  if cluster_type == 'GMM':\n",
    "    model = mixture.GaussianMixture(n_components=num_cluster, covariance_type='full', n_init=100)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'k-means':\n",
    "    model=KMeans(n_clusters=num_cluster, n_init=10, max_iter=10000)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'HS':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster, linkage='single')\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'H':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'spectral':\n",
    "    model = SpectralClustering(assign_labels='discretize', n_clusters=num_cluster, random_state=77, n_init=1)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'custom-scan':\n",
    "    td = get_dim(X)\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "      n_components=td,\n",
    "      n_neighbors=d // 2,\n",
    "      max_iter=100000\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(td)])\n",
    "    # visualize_4d(res)\n",
    "    compo = ComponentScan(n_neighbor=50, step=50).fit(res)\n",
    "    compo.predict()\n",
    "    return compo.components_\n",
    "  elif cluster_type == 'PCAH':\n",
    "    tmp = pd.DataFrame(PCA(\n",
    "      n_components=3,\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(3)])\n",
    "    return get_cluster(tmp, num_cluster, 'GMM')\n",
    "  elif cluster_type == 'custom':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d, eigen_solver='dense').fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom3d':\n",
    "    td = 3\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom50':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=2 * d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  return labels\n",
    "\n",
    "def join_clusters():\n",
    "  df['cluster'] = [0]*n\n",
    "  data_index = [0] * (int(df.manifold.max()) + 1)\n",
    "  for i in range(n):\n",
    "    index_manifold = int(df.at[i,'manifold'])\n",
    "    if index_manifold!=-1:\n",
    "      df.at[i,'cluster'] = list_labels[index_manifold][data_index[index_manifold]]\n",
    "      data_index[index_manifold]+=1\n",
    "\n",
    "list_labels = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  if final_k_list[i] == 1:\n",
    "    list_labels.append([0] * len(df[df['manifold'] == i]))\n",
    "    continue\n",
    "  labels = get_cluster(df[df['manifold'] == i][[i for i in range(d)]], num_cluster=final_k_list[i], cluster_type=cluster_type[i])\n",
    "  list_labels.append(labels)\n",
    "print('------')\n",
    "print(int(df.manifold.max()) + 1)\n",
    "print('-------')\n",
    "join_clusters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import miniball\n",
    "\n",
    "def get_pca(x):\n",
    "    pca = PCA(n_components = d)\n",
    "    pca.fit_transform(x)\n",
    "    return pca.explained_variance_ratio_, pca.components_\n",
    "\n",
    "THRESHOLD = 0.99\n",
    "def find_normal_vectors(eigens,vectors):\n",
    "  res = sum(eigens)\n",
    "  current = 0\n",
    "  normal_vectors = []\n",
    "  for i in range(0,len(eigens)):\n",
    "    current += eigens[i]\n",
    "    if current/res > THRESHOLD:\n",
    "      for j in range(i+1,len(eigens)):\n",
    "        normal_vectors.append(vectors[j])\n",
    "      break\n",
    "  return normal_vectors\n",
    "# Outputting\n",
    "def get_affine_space(points):\n",
    "  X = points\n",
    "  s, v = get_pca(X)\n",
    "  #Finding Normal Vectors using PCA\n",
    "  A = find_normal_vectors(s, v)\n",
    "  #Finding b-s using PCA\n",
    "  b = []\n",
    "  mean = np.mean(points, axis = 0)\n",
    "  for j in range(len(A)):\n",
    "    b.append(np.dot(A[j],mean))\n",
    "  return A, b\n",
    "def get_optimal_miniball(points):\n",
    "  points = np.asarray(points)\n",
    "  minlist = [min(points, key=lambda p: p[j])[j] for j in range(0,d)]\n",
    "  points = [[p[j]-minlist[j] for j in range(0,d)] for p in points]\n",
    "  mb = miniball.Miniball(points)\n",
    "  c = mb.center()\n",
    "  for j in range(0,d):\n",
    "    c[j]+=minlist[j]\n",
    "  r = math.sqrt(mb.squared_radius())\n",
    "  if not mb.is_valid():\n",
    "    print('Possibly invalid!')\n",
    "  print('Relative error', mb.relative_error())\n",
    "  return c,r\n",
    "def spherical_measure(data):\n",
    "  X = np.array(data)\n",
    "  n = len(X)\n",
    "  d = len(X[0])\n",
    "  c,r = get_optimal_miniball(X)\n",
    "  c = np.array(c)\n",
    "  r = np.array(r)\n",
    "  SSE = np.array([(np.linalg.norm(X[i]-c)-r)**2 for i in range(n)]).sum()\n",
    "  total = n * (r**2)\n",
    "  print(f'error divided by total: {SSE / total}')\n",
    "  print(f'error: {SSE / n}')\n",
    "  return SSE/total\n",
    "def get_manifold_type(data, mcl_d, acceptable_error=1e-3):\n",
    "  X = data.to_numpy()\n",
    "  pca_d = d-len(find_normal_vectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "  if spherical_measure(data) < acceptable_error:\n",
    "    print(f'{pca_d} - {mcl_d}')\n",
    "    return 'Sphere'\n",
    "  if pca_d > mcl_d:\n",
    "    return 'Complex'\n",
    "  return 'Affine'\n",
    "\n",
    "vectors = [[[] for j in range(0,final_k_list[i])] for i in range(int(df.manifold.max()) + 1)]\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "outlier = []\n",
    "for i in range(n):\n",
    "  if int(df.at[i, 'manifold']) == -1:\n",
    "    outlier.append(i + 1)\n",
    "  else:\n",
    "    vectors[int(df.at[i, 'manifold'])][int(df.at[i, 'cluster'])].append(i + 1)\n",
    "\n",
    "with open('./output.txt', 'w') as f:\n",
    "  print(f'{n} {int(df.manifold.max()) + 1}', file=f)\n",
    "  for i in range(int(df.manifold.max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[j for j in range(d)]]\n",
    "    if D[i] == 6:\n",
    "      D[i] = get_dim(X, max_d=15)\n",
    "    manifold_type = get_manifold_type(X, D[i])\n",
    "    if manifold_type == 'Complex':\n",
    "      dimension = D[i]\n",
    "    else:\n",
    "      dimension = d - len(find_normal_vectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "    print(f'{dimension} ' + str(final_k_list[i]) + f' {manifold_type}', file=f)\n",
    "    if manifold_type != 'Complex':\n",
    "      A, B = get_affine_space(X)\n",
    "      for j in range(len(A)):\n",
    "        print(' '.join(list(map(str,A[j]))), file=f)\n",
    "      print(' '.join(list(map(str,B))), file=f)\n",
    "    if manifold_type == 'Sphere':\n",
    "      c, r = get_optimal_miniball(X)\n",
    "      print(' '.join(list(map(str, c))) + ' ' + str(r), file=f)\n",
    "    for j in range(0,final_k_list[i]):\n",
    "      print(str(len(vectors[i][j])) + ' ' + ' '.join(list(map(str, vectors[i][j]))), file=f)\n",
    "  print(str(len(outlier)) + ' ' + ' '.join(list(map(str, outlier))), file=f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}