{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "OptimizationA.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "qw9heMTlnccf",
    "BIfVETB9X19k",
    "KIB_rl2kX7W0",
    "2qV89xYLYDWu",
    "0t87F114Yi-L",
    "Nb_Nf5VVayMG",
    "hccGGCAcZ8D8"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn import preprocessing  # to normalise existing X\n",
    "import random\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import mixture\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import LocallyLinearEmbedding, trustworthiness\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "id": "jCjb0Crx7hKU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "id": "2qV89xYLYDWu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.sparse import csgraph, csc_matrix\n",
    "import scipy.sparse.linalg as LA\n",
    "import collections\n",
    "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
    "import scipy\n",
    "\n",
    "\n",
    "def mds_reduction(data, target_dimension):\n",
    "  return pd.DataFrame(MDS(n_components=target_dimension,eps=1e-4,n_init=15).fit_transform(data))\n",
    "#PCA get principal components Functions\n",
    "def get_pca(x):\n",
    "    pca = PCA(n_components = d)\n",
    "    pca.fit_transform(x)\n",
    "    # print(pca.explained_variance_ratio_)\n",
    "    return pca.explained_variance_ratio_, pca.components_\n",
    "#Identifying Components with small Eigenvalue\n",
    "THRESHOLD = 0.99\n",
    "def find_normal_vectors(eigens, vectors):\n",
    "  res = sum(eigens)\n",
    "  current = 0\n",
    "  normal_vectors = []\n",
    "  for i in range(0,len(eigens)):\n",
    "    current += eigens[i]\n",
    "    if current/res > THRESHOLD:\n",
    "      for j in range(i+1,len(eigens)):\n",
    "        normal_vectors.append(vectors[j])\n",
    "      break\n",
    "  return normal_vectors\n",
    "def normalized(X, c):\n",
    "  for i in range(len(X)):\n",
    "    X.iloc[i]-= c\n",
    "  return preprocessing.normalize(X)\n",
    "def variance(data):\n",
    "  mean = sum(data) / len(data)\n",
    "  deviations = [(x - mean) ** 2 for x in data]\n",
    "  variance = sum(deviations) / len(data)\n",
    "  return variance\n",
    "def get_reduced(X, target_dimension, reduction_type):\n",
    "  X_transformed = []\n",
    "  if reduction_type == 'iso':\n",
    "    embedding = Isomap(n_components=target_dimension, n_neighbors=10)\n",
    "    X_transformed = embedding.fit_transform(X)\n",
    "  elif reduction_type == 'pca':\n",
    "    transformer = PCA(n_components=target_dimension)\n",
    "    X_transformed = transformer.fit_transform(X)\n",
    "  elif reduction_type == 'k-pca':\n",
    "    transformer = KernelPCA(n_components=target_dimension, kernel='rbf')\n",
    "    X_transformed = transformer.fit_transform(X)\n",
    "  elif reduction_type == 'tsne':\n",
    "    X_transformed = TSNE(n_components=target_dimension, learning_rate='auto', init='pca').fit_transform(X)\n",
    "  elif reduction_type == 'mds':\n",
    "    X_transformed = mds_reduction(X,target_dimension)\n",
    "  elif reduction_type == 'LLE':\n",
    "    X_transformed = LocallyLinearEmbedding(n_components=target_dimension, n_neighbors=30).fit_transform(X)\n",
    "  return X_transformed\n",
    "def get_cluster(X, num_cluster, cluster_type):\n",
    "  if cluster_type == 'GMM':\n",
    "    model = mixture.GaussianMixture(n_components=num_cluster, covariance_type='full', n_init=100)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'k-means':\n",
    "    model=KMeans(n_clusters=num_cluster, n_init=10, max_iter=10000)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'HS':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster, linkage='single')\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'H':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'spectral':\n",
    "    model = SpectralClustering(assign_labels='discretize', n_clusters=num_cluster, random_state=77, n_init=1)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'custom-scan':\n",
    "    td = get_dim(X)\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "      n_components=td,\n",
    "      n_neighbors=d // 2,\n",
    "      max_iter=100000\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(td)])\n",
    "    # visualize_4d(res)\n",
    "    compo = ComponentScan(n_neighbor=50, step=50).fit(res)\n",
    "    compo.predict()\n",
    "    return compo.components_\n",
    "  elif cluster_type == 'PCAH':\n",
    "    tmp = pd.DataFrame(PCA(\n",
    "      n_components=3,\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(3)])\n",
    "    return get_cluster(tmp, num_cluster, 'GMM')\n",
    "  elif cluster_type == 'custom':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom3d':\n",
    "    td = 3\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom50':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=2 * d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  return labels\n",
    "def show_distance_graph(X):\n",
    "  neigh = NearestNeighbors(n_neighbors=2)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors(X)\n",
    "  # Plotting K-distance Graph\n",
    "  distances = np.sort(distances, axis=0)\n",
    "  distances = distances[:,1]\n",
    "  print(distances[-700:])\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.plot(distances)\n",
    "  plt.title('K-distance Graph',fontsize=20)\n",
    "  plt.xlabel('Data Points sorted by distance',fontsize=14)\n",
    "  plt.ylabel('Epsilon',fontsize=14)\n",
    "  plt.show()\n",
    "  #Visualization in 4D\n",
    "def visualize_4d(frame, hot=True):\n",
    "  fig = plt.figure(figsize=(7, 7))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "  x = np.array(frame.iloc[:,0])\n",
    "  if len(frame.columns) > 1:\n",
    "    y = np.array(frame.iloc[:,1])\n",
    "  if len(frame.columns) > 2:\n",
    "    z = np.array(frame.iloc[:,2])\n",
    "  if len(frame.columns) == 1:\n",
    "    img = ax.scatter(x, x, s=2)\n",
    "  if len(frame.columns) == 2:\n",
    "    img = ax.scatter(x, y, s=2)\n",
    "  elif len(frame.columns) == 3:\n",
    "    img = ax.scatter(x, y, z, s=2)\n",
    "  else:\n",
    "    c = np.array(frame.iloc[:,3])\n",
    "    if hot:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap=plt.hot(), s=2)\n",
    "    else:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap='viridis', s=2)\n",
    "  plt.show()\n",
    "def merge(X, col, val_list):\n",
    "  def get_col(row):\n",
    "    for ind in range(len(val_list)):\n",
    "      if row[col] in val_list[ind]:\n",
    "        return 100 + ind\n",
    "    return row[col]\n",
    "  X[col] = X.apply(get_col, axis=1)\n",
    "  X[col] = LabelEncoder().fit_transform(X[col])\n",
    "  X[col] -= 1\n",
    "  return X\n",
    "def get_local_intrinsic_dimension(data, n_neighbors=5):\n",
    "  X = np.array(data)\n",
    "  M = np.matrix(X)\n",
    "  L = n_neighbors\n",
    "  if not isinstance(L, (int, np.integer))  or L<0:\n",
    "    return 'n_neighbors must be a positive integer!'\n",
    "  neigh = NearestNeighbors(n_neighbors=L)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors()\n",
    "  mean = [np.mean([M[indices[i][j]] for j in range(L)],axis=0) for i in range(len(X))]\n",
    "  #Calculating the local covariance matrix for each point\n",
    "  C = [1/L * sum([np.dot( (M[indices[i][j],:]-mean[i]).transpose() , (M[indices[i][j],:]-mean[i]) ) for j in range(L)]) for i in range(len(X))]\n",
    "\n",
    "  #Intrinsic Dimension Estimation\n",
    "  THRESHOLD = 0.05\n",
    "  intrinsic_dimension = [0] * len(X)\n",
    "\n",
    "  E = [sorted(LA.eigsh(C[i])[0], reverse=True) for i in range(len(X))]\n",
    "  for i in range(len(X)):\n",
    "    eigen_list = E[i]\n",
    "    d = len(eigen_list)\n",
    "    first_eigenvalue= eigen_list[0]\n",
    "    for j in range(1,d):\n",
    "      if eigen_list[j]/first_eigenvalue < THRESHOLD:\n",
    "        intrinsic_dimension[i]=j\n",
    "        break\n",
    "    if intrinsic_dimension[i]==0:\n",
    "      intrinsic_dimension[i]=d\n",
    "  return np.array(intrinsic_dimension)\n",
    "def is_manifold(data, n_neighbors=5, error=0.05, is_calculated=False):\n",
    "  #Assuming data is consisted of submanifolds with DIFFERENT dimensions OR is just consisted of one manifold\n",
    "  if not is_calculated:\n",
    "    ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  else:\n",
    "    ID = data['local_dim'].to_numpy()\n",
    "  total = len(ID)\n",
    "  # n_manifolds = max(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  print(counter)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  accuracy = counter[dimension]/total\n",
    "  if accuracy > 1-error:\n",
    "    # print(f'Accuracy: {accuracy}. Data resides on a {dimension}-dimensional manifold!')\n",
    "    return True,accuracy\n",
    "  # print(f'Accuracy: {accuracy} -> Inconclusive!')\n",
    "  return False,accuracy\n",
    "def predict_n_clusters(data, method='eigengap', n_neighbors=5, plot=False):\n",
    "  if method=='eigengap':\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(data)\n",
    "    distances, neighbors = nbrs.kneighbors(data)\n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for i in range(len(data)):\n",
    "      for j in neighbors[i]:\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "        val.append(1)\n",
    "    mat = csc_matrix((np.array(val), (np.array(row), np.array(col))), shape=(len(data), len(data)))\n",
    "    k, _, _ = eigengap_heuristic(mat, plot=plot)\n",
    "    return k\n",
    "  return 'Invalid Combination of algorithm and method'\n",
    "def showSilouette(X, model_list, plot=True):\n",
    "  silouette = [silhouette_score(X, model_list[i].fit_predict(X)) for i in range(len(model_list))]\n",
    "  if plot:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.plot(range(2, len(model_list)+2),silouette,'gs-')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Curve')\n",
    "    plt.show()\n",
    "  return silouette.index(max(silouette))+2\n",
    "def getAffinityMatrix(coordinates, n_neighbors):\n",
    "  A = kneighbors_graph(coordinates, n_neighbors=n_neighbors, mode='connectivity', include_self=False).toarray()\n",
    "  for i in range(len(A)):\n",
    "    for j in range(len(A[0])):\n",
    "      if A[i][j] == 1:\n",
    "        A[j][i] = 1\n",
    "  return A\n",
    "def eigengap_heuristic(A, plot = True):\n",
    "    L = csgraph.laplacian(A, normed=True)\n",
    "    # print(L)\n",
    "    # n_components = A.shape[0]\n",
    "    # LM parameter : Eigenvalues with largest magnitude (eigs, eigsh), that is, largest eigenvalues in\n",
    "    # the euclidean norm of complex numbers.\n",
    "    eigenvalues = scipy.linalg.eigh(L, eigvals_only=True)\n",
    "    print(eigenvalues[:10])\n",
    "    # eigenvalues = np.negative(eigenvalues[::-1])\n",
    "    # eigenvalues, eigenvectors = LA.einp.negative(L)g(L)\n",
    "    if plot:\n",
    "        plt.title('Largest eigen values of input matrix')\n",
    "        plt.scatter(np.arange(len(eigenvalues))[:10], eigenvalues[:10])\n",
    "        plt.grid()\n",
    "\n",
    "    # Identify the optimal number of clusters as the index corresponding\n",
    "    # to the larger gap between eigen values\n",
    "    max_gap = 0\n",
    "    gap_pre_index = 0\n",
    "    for i in range(1, 6):\n",
    "        gap = np.abs(eigenvalues[i] / eigenvalues[i - 1])\n",
    "        if gap > max_gap:\n",
    "            max_gap = gap\n",
    "            gap_pre_index = i\n",
    "\n",
    "    return gap_pre_index\n",
    "def predict_n_clusters(data, plot=False, **kwargs):\n",
    "  return eigengap_heuristic(getAffinityMatrix(data, n_neighbors=15), plot)\n",
    "class ComponentScan:\n",
    "\n",
    "  def __init__(self, n_neighbor=50, step=50):\n",
    "    self.neighbors = None\n",
    "    self.points = None\n",
    "    self.n_neighbor = n_neighbor\n",
    "    self.step = step\n",
    "    self.components_ = None\n",
    "\n",
    "  def fit(self, X):\n",
    "    self.neighbors = []\n",
    "    for i in range(5):\n",
    "      nbrs = NearestNeighbors(n_neighbors=self.n_neighbor + i * self.step, algorithm='brute').fit(X)\n",
    "      self.neighbors.append(nbrs.kneighbors(X)[1])\n",
    "    self.points = X.to_numpy()\n",
    "    self.components_ = np.full((len(X)), -1)\n",
    "    return self\n",
    "\n",
    "  def predict(self):\n",
    "    cnt = 0\n",
    "    ind = 0\n",
    "    c = -1\n",
    "    rep = 0\n",
    "    while True:\n",
    "      while ind < len(self.points):\n",
    "        if self.components_[ind] == -1:\n",
    "          break\n",
    "        ind += 1\n",
    "      if ind == len(self.points):\n",
    "        break\n",
    "      stack = [ind]\n",
    "      combo = []\n",
    "      cnt = 0\n",
    "      c += 1\n",
    "      while len(stack) > 0:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "          print(f'{cnt} - {len(stack)}')\n",
    "        v = stack.pop()\n",
    "        self.components_[v] = c\n",
    "        for u in self.neighbors[rep][v]:\n",
    "          if self.components_[u] == -1:\n",
    "            stack.append(u)\n",
    "            combo.append(u)\n",
    "            self.components_[u] = c\n",
    "      if len(combo) < 100:\n",
    "        rep += 1\n",
    "        if rep == 5:\n",
    "          rep = 0\n",
    "        for c in combo:\n",
    "          self.components_[c] = -1\n",
    "      else:\n",
    "        rep = 0\n",
    "    return c + 1\n",
    "def get_dim(X, threshold=0.95, print_scores=False):\n",
    "  for td in range(1, 15):\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=50, max_iter=10000).fit_transform(X),\n",
    "                       columns=[i for i in range(td)])\n",
    "    score = trustworthiness(X, res, n_neighbors=d)\n",
    "    if print_scores:\n",
    "      print(f'dim score {td}: {score}')\n",
    "    if score >= threshold:\n",
    "      return td\n",
    "  return d"
   ],
   "metadata": {
    "id": "lreiVAqgbFK7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open Input"
   ],
   "metadata": {
    "id": "E59D74nTYeiL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Input\n",
    "file = open('./R43.txt','r')\n",
    "d,n,m,k,p = list(file.readline().split())\n",
    "d,n,p,k = map(int, [d, n, p, k])\n",
    "k_list = list(map(int,file.readline().split()))\n",
    "ar=[]\n",
    "for i in range(0,n):\n",
    "  ar.append(list(map(float,file.readline().split())))\n",
    "df= pd.DataFrame(ar)\n",
    "df.describe()"
   ],
   "metadata": {
    "id": "lU5fWrUlu-e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                 0             1             2             3             4   \\\ncount  83732.000000  83732.000000  83732.000000  83732.000000  83732.000000   \nmean     900.793973     27.168648     -0.136205     12.758157     28.076036   \nstd      552.972090     24.627435     22.745172     18.809216     20.632893   \nmin    -1266.120000    -94.550000   -137.240000    -98.180000    -97.810000   \n25%      479.090000     16.730000    -13.630000      4.090000     16.760000   \n50%      887.470000     24.500000      2.730000     11.360000     30.050000   \n75%     1367.420000     38.340000     11.070000     19.700000     37.012500   \nmax     1971.350000    138.230000    110.750000     97.550000    107.180000   \n\n                 5             6             7             8             9   \\\ncount  83732.000000  83732.000000  83732.000000  83732.000000  83732.000000   \nmean      59.632216     -6.981060     23.216674     85.848005     44.444390   \nstd       26.120597     27.123498     27.214087     32.092357     23.228691   \nmin     -107.650000   -131.340000   -110.140000   -114.640000    -86.630000   \n25%       50.220000    -19.140000      3.020000     66.270000     32.330000   \n50%       62.980000     -6.210000     26.730000     84.430000     46.950000   \n75%       75.610000      6.410000     41.010000    110.202500     54.350000   \nmax      161.280000    119.280000    123.420000    181.690000    125.480000   \n\n       ...            90            91            92            93  \\\ncount  ...  83732.000000  83732.000000  83732.000000  83732.000000   \nmean   ...    -57.496764      3.075474     43.393192     47.202271   \nstd    ...     42.475659     23.810814     24.358144     32.725718   \nmin    ...   -187.660000   -103.530000   -105.130000   -138.580000   \n25%    ...    -86.120000    -13.810000     25.820000     28.850000   \n50%    ...    -48.630000     -1.150000     45.380000     42.310000   \n75%    ...    -30.830000     14.062500     65.090000     71.160000   \nmax    ...    154.710000    122.590000    117.210000    138.690000   \n\n                 94            95            96            97            98  \\\ncount  83732.000000  83732.000000  83732.000000  83732.000000  83732.000000   \nmean      30.155224     19.171794     41.976750     21.771674     84.254643   \nstd       27.393103     22.055959     28.814611     18.946450     34.108199   \nmin     -114.280000   -109.920000    -99.850000    -93.430000   -114.850000   \n25%       12.797500      8.660000     23.940000      8.500000     63.460000   \n50%       27.770000     19.980000     39.470000     22.430000     86.430000   \n75%       49.780000     31.360000     62.840000     35.180000    106.080000   \nmax      126.030000     98.420000    136.020000     92.820000    178.640000   \n\n                 99  \ncount  83732.000000  \nmean      14.056604  \nstd       22.180713  \nmin     -109.690000  \n25%        3.447500  \n50%       15.690000  \n75%       27.350000  \nmax       97.530000  \n\n[8 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>...</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n      <td>83732.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>900.793973</td>\n      <td>27.168648</td>\n      <td>-0.136205</td>\n      <td>12.758157</td>\n      <td>28.076036</td>\n      <td>59.632216</td>\n      <td>-6.981060</td>\n      <td>23.216674</td>\n      <td>85.848005</td>\n      <td>44.444390</td>\n      <td>...</td>\n      <td>-57.496764</td>\n      <td>3.075474</td>\n      <td>43.393192</td>\n      <td>47.202271</td>\n      <td>30.155224</td>\n      <td>19.171794</td>\n      <td>41.976750</td>\n      <td>21.771674</td>\n      <td>84.254643</td>\n      <td>14.056604</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>552.972090</td>\n      <td>24.627435</td>\n      <td>22.745172</td>\n      <td>18.809216</td>\n      <td>20.632893</td>\n      <td>26.120597</td>\n      <td>27.123498</td>\n      <td>27.214087</td>\n      <td>32.092357</td>\n      <td>23.228691</td>\n      <td>...</td>\n      <td>42.475659</td>\n      <td>23.810814</td>\n      <td>24.358144</td>\n      <td>32.725718</td>\n      <td>27.393103</td>\n      <td>22.055959</td>\n      <td>28.814611</td>\n      <td>18.946450</td>\n      <td>34.108199</td>\n      <td>22.180713</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1266.120000</td>\n      <td>-94.550000</td>\n      <td>-137.240000</td>\n      <td>-98.180000</td>\n      <td>-97.810000</td>\n      <td>-107.650000</td>\n      <td>-131.340000</td>\n      <td>-110.140000</td>\n      <td>-114.640000</td>\n      <td>-86.630000</td>\n      <td>...</td>\n      <td>-187.660000</td>\n      <td>-103.530000</td>\n      <td>-105.130000</td>\n      <td>-138.580000</td>\n      <td>-114.280000</td>\n      <td>-109.920000</td>\n      <td>-99.850000</td>\n      <td>-93.430000</td>\n      <td>-114.850000</td>\n      <td>-109.690000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>479.090000</td>\n      <td>16.730000</td>\n      <td>-13.630000</td>\n      <td>4.090000</td>\n      <td>16.760000</td>\n      <td>50.220000</td>\n      <td>-19.140000</td>\n      <td>3.020000</td>\n      <td>66.270000</td>\n      <td>32.330000</td>\n      <td>...</td>\n      <td>-86.120000</td>\n      <td>-13.810000</td>\n      <td>25.820000</td>\n      <td>28.850000</td>\n      <td>12.797500</td>\n      <td>8.660000</td>\n      <td>23.940000</td>\n      <td>8.500000</td>\n      <td>63.460000</td>\n      <td>3.447500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>887.470000</td>\n      <td>24.500000</td>\n      <td>2.730000</td>\n      <td>11.360000</td>\n      <td>30.050000</td>\n      <td>62.980000</td>\n      <td>-6.210000</td>\n      <td>26.730000</td>\n      <td>84.430000</td>\n      <td>46.950000</td>\n      <td>...</td>\n      <td>-48.630000</td>\n      <td>-1.150000</td>\n      <td>45.380000</td>\n      <td>42.310000</td>\n      <td>27.770000</td>\n      <td>19.980000</td>\n      <td>39.470000</td>\n      <td>22.430000</td>\n      <td>86.430000</td>\n      <td>15.690000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1367.420000</td>\n      <td>38.340000</td>\n      <td>11.070000</td>\n      <td>19.700000</td>\n      <td>37.012500</td>\n      <td>75.610000</td>\n      <td>6.410000</td>\n      <td>41.010000</td>\n      <td>110.202500</td>\n      <td>54.350000</td>\n      <td>...</td>\n      <td>-30.830000</td>\n      <td>14.062500</td>\n      <td>65.090000</td>\n      <td>71.160000</td>\n      <td>49.780000</td>\n      <td>31.360000</td>\n      <td>62.840000</td>\n      <td>35.180000</td>\n      <td>106.080000</td>\n      <td>27.350000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1971.350000</td>\n      <td>138.230000</td>\n      <td>110.750000</td>\n      <td>97.550000</td>\n      <td>107.180000</td>\n      <td>161.280000</td>\n      <td>119.280000</td>\n      <td>123.420000</td>\n      <td>181.690000</td>\n      <td>125.480000</td>\n      <td>...</td>\n      <td>154.710000</td>\n      <td>122.590000</td>\n      <td>117.210000</td>\n      <td>138.690000</td>\n      <td>126.030000</td>\n      <td>98.420000</td>\n      <td>136.020000</td>\n      <td>92.820000</td>\n      <td>178.640000</td>\n      <td>97.530000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38.34206958  38.36590935  38.39835283  38.41663962  38.49517762\n",
      "  38.4982584   38.55331244  38.59629516  38.60314365  38.67371717\n",
      "  38.67639202  38.72456197  38.72485765  38.82401448  38.85240276\n",
      "  38.89265612  38.92544027  38.93205106  38.97546279  39.03829786\n",
      "  39.0406647   39.04300193  39.04300193  39.15225281  39.16314594\n",
      "  39.23463393  39.27079831  39.33556279  39.39274299  39.3962752\n",
      "  39.42861905  39.44536982  39.44536982  39.46098073  39.51240565\n",
      "  39.56960829  39.61924785  39.63734476  39.65800676  39.75907569\n",
      "  39.83832953  39.87348743  39.90150122  39.93116202  39.98838956\n",
      "  40.08893488  40.11949651  40.20954737  40.21144738  40.28046176\n",
      "  40.29842553  40.35789142  40.38734084  40.40243062  40.43800811\n",
      "  40.51958169  40.5223099   40.75181836  40.76843141  40.80465782\n",
      "  40.82308048  40.98005246  41.0954523   41.14917618  41.19705936\n",
      "  41.2098629   41.32568935  41.33285739  41.37118925  41.41932037\n",
      "  41.69336278  41.77648382  41.80818221  41.81857243  41.87969436\n",
      "  41.94093227  42.11856123  42.12929147  42.57336609  42.63651369\n",
      "  42.7434299   42.85760026  42.87873482  43.00614956  43.09013228\n",
      "  43.25639606  43.37588501  43.62192912  43.68341104  44.08447459\n",
      "  44.44657917  44.81086587  44.96685557  45.02666987  45.46297835\n",
      "  45.9718577   46.31031203  46.90565851  47.66356155  48.88308705\n",
      " 564.44120704 573.05179792 590.04605269 593.79515382 606.39324304\n",
      " 606.76919203 608.33773202 608.750023   610.28511878 610.38990891\n",
      " 612.04397219 613.4767038  616.24724657 619.4275454  619.9075552\n",
      " 621.36885157 622.03657738 622.30191378 623.74231627 623.85346813\n",
      " 625.90981084 625.99342536 626.02220432 626.6972265  626.78868832\n",
      " 627.60706226 628.6907347  628.91945931 629.63386321 631.79383425\n",
      " 632.05123867 633.361887   633.42514349 634.31284048 635.2922067\n",
      " 638.44626148 638.81469872 638.9025673  639.4072943  639.70553585\n",
      " 640.21012168 640.64061938 641.32378897 641.57754496 642.58742028\n",
      " 642.93600708 643.80940503 644.7046219  644.71734442 645.23182098\n",
      " 645.27052327 645.57282161 645.86500207 646.49321458 646.65853091\n",
      " 647.67802348 647.70743504 648.22719597 649.43082595 649.87739151\n",
      " 650.23408969 650.73065711 650.73253131 652.08423712 652.39513878\n",
      " 652.68145714 653.34686898 653.8373521  653.86345111 654.09300065\n",
      " 654.57846925 654.62110973 654.64435566 655.27299654 655.86097727\n",
      " 655.95594814 656.23531168 656.67075083 656.71731438 656.93025436\n",
      " 657.27411367 657.39321224 658.68929284 659.77136169 659.9290627\n",
      " 660.25549926 661.08504718 661.0857309  661.0857309  661.25744941\n",
      " 661.35055576 661.660845   661.71016163 662.36016154 662.60169114\n",
      " 662.63376393 662.9425503  663.68356421 663.84857626 663.97691617\n",
      " 664.13254611 664.14935978 664.16296901 664.64480943 664.72887074\n",
      " 665.05502915 665.61204181 665.66352446 666.26933788 666.64853701\n",
      " 666.64853701 667.02568099 667.94664091 668.14949637 668.30075879\n",
      " 668.77160578 668.77160578 668.77477173 669.00123191 669.01073385\n",
      " 669.8494666  669.96276083 670.03752111 670.0515913  670.09127595\n",
      " 670.10499804 670.53372905 671.72248615 672.21138483 672.33893781\n",
      " 672.94353664 673.49958396 673.95731898 674.52454121 674.58071667\n",
      " 674.86838465 675.03474718 675.30634071 675.8537213  675.93884457\n",
      " 676.83381454 677.16394669 677.88401537 677.92214649 678.17694505\n",
      " 678.73747546 678.78371158 678.93554414 679.15874543 679.32285756\n",
      " 679.43112491 679.62042833 680.62520428 681.00267547 681.40164514\n",
      " 681.47381036 681.66617688 681.93393177 682.03914067 682.08117017\n",
      " 682.19443805 682.7812682  683.13687311 683.13687311 683.46483735\n",
      " 683.48727479 683.51433818 684.2109223  684.33527872 685.01705701\n",
      " 685.01705701 685.48829034 685.93438841 686.24060372 686.35009929\n",
      " 686.35145676 686.41607011 686.5568755  686.78419034 687.01810289\n",
      " 687.53251501 687.64595105 687.76565449 688.14619609 688.15520045\n",
      " 688.198339   688.3037931  688.35432969 688.35432969 688.76305926\n",
      " 689.02193637 689.02193637 689.03961882 689.03961882 689.30642025\n",
      " 689.5800211  690.16305066 690.43324739 690.60422935 690.99680904\n",
      " 691.12647967 691.14439758 691.2110789  691.93950588 692.3446516\n",
      " 692.36071451 692.49177995 692.88653884 693.08113342 693.08113342\n",
      " 693.11544428 693.76560292 694.1323134  694.17096921 694.34799553\n",
      " 694.73838112 695.03722526 695.03722526 695.31237016 695.37272523\n",
      " 696.13015478 696.36419803 696.37025001 696.43074164 696.70150438\n",
      " 696.9726542  697.17343395 697.17343395 697.20914767 697.57576026\n",
      " 697.57576026 697.67902255 697.73052742 697.87934831 698.51948233\n",
      " 698.61015166 699.16268622 700.78391834 700.79720055 700.79720055\n",
      " 700.84553962 700.84553962 700.94140832 700.98639216 701.10835026\n",
      " 701.38844765 701.61268119 702.34719975 702.77916894 702.83161106\n",
      " 703.07845679 703.08724139 703.26123375 703.36247554 703.41856231\n",
      " 703.41856231 703.64584394 704.00696687 704.2377475  704.49642554\n",
      " 704.53218017 704.67539151 705.14782422 705.20764268 705.52700565\n",
      " 705.52700565 705.5927737  705.62880305 706.00732574 706.02930796\n",
      " 706.2395772  706.39419696 707.12346312 707.56267652 707.62466294\n",
      " 708.04479512 708.04479512 708.08461952 708.08461952 708.11492266\n",
      " 708.46054223 708.59414935 708.80428152 708.86338204 708.88089578\n",
      " 709.04012348 709.10138182 709.69606544 709.87721417 710.23540344\n",
      " 710.39909086 710.99977876 711.23473544 711.97540175 712.00716541\n",
      " 712.25515723 712.42440925 712.5063258  712.9296048  713.36849902\n",
      " 713.76040294 713.77092383 713.91794227 714.2645253  714.52517143\n",
      " 714.72209998 715.14538934 715.16231249 715.16231249 715.33725207\n",
      " 715.42705938 715.65359665 715.65359665 715.67180739 716.00200984\n",
      " 716.55718006 716.64790609 716.71956992 716.92824934 717.43435512\n",
      " 717.43523812 717.54597072 717.62172786 718.07713555 718.10769332\n",
      " 718.21872344 718.22699107 718.47581247 718.80950536 718.89037294\n",
      " 719.15645447 719.35462006 719.35462006 719.80192393 720.17502414\n",
      " 720.79538289 720.8671062  721.6773333  721.71833474 722.17783405\n",
      " 722.34423352 722.36010749 722.93209626 723.02631709 723.11370185\n",
      " 723.23052113 723.23052113 723.63959794 724.04315707 724.60181569\n",
      " 724.90248317 725.11470968 725.14162417 725.60021472 725.62207002\n",
      " 725.79569563 725.79723505 725.84766956 725.93419805 726.15116388\n",
      " 726.48302726 726.68342048 726.83004733 727.2643221  727.53786822\n",
      " 727.54946038 727.54946038 727.58994104 727.58994104 728.37657197\n",
      " 728.44752227 728.6854086  729.29644864 729.29975977 730.13367858\n",
      " 730.32645228 730.34872212 730.65757554 731.11962981 731.11962981\n",
      " 731.49524722 731.50767166 731.66944367 731.9259399  732.10124546\n",
      " 732.10124546 732.56082921 733.09574409 733.35767856 733.35767856\n",
      " 733.35989691 733.63061393 733.88464059 733.88464059 734.00339209\n",
      " 734.05327157 734.12035151 734.14677048 734.16255727 734.57966042\n",
      " 734.69393757 735.50528951 735.79184951 736.02232806 736.07603941\n",
      " 736.13065165 736.24165652 736.24165652 736.29014784 736.32947401\n",
      " 736.45440511 736.56008214 736.59604364 736.65694757 736.94889009\n",
      " 736.98403972 737.2465865  737.27017043 737.46339841 737.49608867\n",
      " 737.87858032 738.10488794 738.28716209 738.71536156 738.71536156\n",
      " 739.30745208 739.56385032 739.70465322 739.84658964 739.87521711\n",
      " 739.97115167 740.00397607 740.02435575 740.45793628 741.15452053\n",
      " 741.42884541 741.58374969 742.01345048 742.01345048 742.18378169\n",
      " 742.35283902 742.38347422 742.38347422 742.4237307  742.79992481\n",
      " 742.8068817  743.11850798 743.4468782  743.49582218 743.68246503\n",
      " 744.19641493 744.19641493 744.42168131 744.52256702 744.79066663\n",
      " 745.24449572 745.33635615 745.82058875 745.83422769 746.10250596\n",
      " 746.16660325 746.44461503 746.7091796  746.98729882 747.32190996\n",
      " 747.39335788 747.82946117 747.82946117 747.88435757 748.46858732\n",
      " 748.77616996 748.78540123 748.9340487  749.74232847 749.78316032\n",
      " 750.18261244 750.1884158  750.1884158  750.54506094 750.60899895\n",
      " 750.62098592 750.96082394 751.07636176 751.27136356 751.34525213\n",
      " 751.5318149  751.55890614 751.61889771 751.83952822 752.02418345\n",
      " 752.22986706 752.452366   752.5456331  752.7151968  752.76421195\n",
      " 752.76421195 752.88237933 752.89313452 753.08614521 753.37315827\n",
      " 753.4124912  753.67538881 753.8189591  754.08665132 754.08665132\n",
      " 754.09043165 754.09043165 754.61520751 755.07618582 755.20304588\n",
      " 755.28816547 755.44476231 755.82210936 755.87075972 755.94148702\n",
      " 756.16397441 756.17900883 756.32553454 756.81524786 757.29517766\n",
      " 758.61662004 758.67494172 758.69632074 758.98470762 759.10271123\n",
      " 759.88103608 760.28656328 760.28996863 760.45609965 760.6806738\n",
      " 762.16557361 762.43556246 762.48679274 762.53527184 762.74868981\n",
      " 762.74868981 763.1457674  763.6931882  763.74855142 763.99935988\n",
      " 764.09628588 764.13966564 764.22834454 764.5278267  764.68076411\n",
      " 766.17714029 766.22036426 766.27343162 766.69573072 766.8772731\n",
      " 766.94766399 766.94766399 767.00375182 767.24534316 767.41280189\n",
      " 767.78187143 768.33071649 768.9477083  769.09044442 769.56235089\n",
      " 770.15405277 770.23917571 770.64598812 772.30843495 772.36971555\n",
      " 772.79420948 773.04900065 773.20603541 773.90202125 774.01308012\n",
      " 776.38693633 777.25710624 777.28092644 777.56890756 777.90712614\n",
      " 778.19141077 779.35697238 779.9736884  780.19867707 780.83814033\n",
      " 780.95420973 780.97701592 781.51289414 781.61114366 783.03218427\n",
      " 784.04812397 784.32150716 787.34999257 787.49649694 788.6111136\n",
      " 791.13801457 791.53315704 791.75060846 792.75665428 793.7998179\n",
      " 794.27592668 796.51038355 798.49806211 805.72463187 811.62511753]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(df[[i for i in range(d)]])\n",
    "show_distance_graph(df)\n",
    "distances, indices = nbrs.kneighbors(df)\n",
    "out = 0\n",
    "for i in range(n):\n",
    "  if distances[i][1] > 100:\n",
    "    df.at[i, 'manifold'] = -1\n",
    "    out += 1\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Submanifolds"
   ],
   "metadata": {
    "id": "YdIkC1Nkll0g",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def find_best_eps(min_sample):\n",
    "  tmp = df[df['manifold'] != -1].copy()\n",
    "  l, r = 0, 80\n",
    "  while (r - l) > 1:\n",
    "    mid = (r + l) / 2\n",
    "    print(mid)\n",
    "    model_name = 'dbscan'\n",
    "    model = DBSCAN(eps=mid, min_samples=min_sample)\n",
    "    model.fit(tmp[[i for i in range(d)]])\n",
    "    tmp['subset'] = model.labels_\n",
    "    print(f\"count: {len(tmp[tmp['subset'] == -1])}\")\n",
    "    print(f\"cluster count: {tmp['subset'].max() + 1}\")\n",
    "    if len(tmp[tmp['subset'] == -1]) > 0:\n",
    "      l = mid\n",
    "    else:\n",
    "      r = mid\n",
    "  return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#DBSCAN\n",
    "# best_eps = find_best_eps(5)\n",
    "best_eps = 49.375\n",
    "model = DBSCAN(eps=best_eps, min_samples=5)\n",
    "model.fit(df[df['manifold'] != -1][[i for i in range(d)]])\n",
    "df.loc[df['manifold'] != -1, 'manifold'] = model.labels_"
   ],
   "metadata": {
    "id": "WLrq5pnTl_Kp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# multi = [0, 1, 4, 5, 14, 20, 32]\n",
    "multi = []\n",
    "if multi is None:\n",
    "  multi = []\n",
    "  for i in range(int(df['manifold'].max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[i for i in range(d)]]\n",
    "    if not is_manifold(X, n_neighbors=d // 2)[0] and not is_manifold(X, n_neighbors=3 * d // 2)[0]:\n",
    "      multi.append(i)\n",
    "      td = 3\n",
    "      res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=20, max_iter=10000).fit_transform(X),\n",
    "                           columns=[i for i in range(td)])\n",
    "      visualize_4d(res)\n",
    "      visualize_4d(X)\n",
    "\n",
    "\n",
    "print(multi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sp = df.copy()\n",
    "# range(int(df.manifold.max()) + 1)\n",
    "for subset in multi:\n",
    "  print(f'processing subset {subset}')\n",
    "  tmp = df[df['manifold'] == subset][[i for i in range(d)]]\n",
    "  td = get_dim(tmp) or 6\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=d // 2,\n",
    "    max_iter=100000\n",
    "  ).fit_transform(\n",
    "    tmp\n",
    "  ), columns=[i for i in range(td)])\n",
    "  # visualize_4d(res)\n",
    "  k = ComponentScan(n_neighbor=50, step=50).fit(res).predict()\n",
    "  print(f'manifold count: {k}')\n",
    "  if k > 10:\n",
    "    continue\n",
    "  sp.loc[sp['manifold'] == subset, 'sub1'] = get_cluster(res, k, 'H')\n",
    "  print(sp.loc[sp['manifold'] == subset, 'sub1'].value_counts())\n",
    "  visualize_4d(pd.DataFrame(get_reduced(tmp, 3, 'pca'), columns=[j for j in range(3)]), hot=False)\n",
    "if len(multi) > 0:\n",
    "  sp['manifold'] = sp.manifold.astype(str) + '-' + sp.sub1.astype(str)\n",
    "  sp = sp.drop(['sub1'], axis=1)\n",
    "  sp['manifold'] = LabelEncoder().fit_transform(sp['manifold'])\n",
    "  sp['manifold'] -= 1\n",
    "  sp['manifold'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# custom cluster for manifold\n",
    "final_k_list = []\n",
    "cluster_type = []\n",
    "for i in range(int(sp.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  if i in [0, 6, 14]:\n",
    "    cluster_type.append('PCAH')\n",
    "    final_k_list.append(3)\n",
    "    continue\n",
    "  X = sp[sp['manifold'] == i][[j for j in range(d)]]\n",
    "  td = get_dim(X) or 6\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=d // 2,\n",
    "    max_iter=100000\n",
    "  ).fit_transform(\n",
    "    X\n",
    "  ), columns=[i for i in range(td)])\n",
    "  k = ComponentScan(n_neighbor=50, step=50).fit(res).predict()\n",
    "  if k < 10:\n",
    "    cluster_type.append('custom-scan')\n",
    "  else:\n",
    "    cluster_type.append('HS')\n",
    "  final_k_list.append(k if k < 10 else 1)"
   ],
   "metadata": {
    "id": "Ft0MXRklKLuC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1000 - 1428\n",
      "2000 - 606\n",
      "2\n",
      "1000 - 1292\n",
      "2000 - 296\n",
      "3\n",
      "1000 - 868\n",
      "2000 - 606\n",
      "4\n",
      "1000 - 1221\n",
      "2000 - 221\n",
      "5\n",
      "1000 - 448\n",
      "6\n",
      "7\n",
      "1000 - 805\n",
      "2000 - 794\n",
      "8\n",
      "1000 - 177\n",
      "1000 - 580\n",
      "9\n",
      "1000 - 2308\n",
      "2000 - 1308\n",
      "3000 - 308\n",
      "10\n",
      "1000 - 985\n",
      "2000 - 1308\n",
      "3000 - 308\n",
      "11\n",
      "1000 - 116\n",
      "2000 - 1054\n",
      "3000 - 54\n",
      "12\n",
      "1000 - 2276\n",
      "2000 - 1315\n",
      "3000 - 317\n",
      "13\n",
      "1000 - 1821\n",
      "2000 - 838\n",
      "14\n",
      "15\n",
      "1000 - 1331\n",
      "2000 - 335\n",
      "16\n",
      "1000 - 1744\n",
      "2000 - 744\n",
      "17\n",
      "1000 - 1594\n",
      "2000 - 965\n",
      "18\n",
      "1000 - 1592\n",
      "2000 - 592\n",
      "19\n",
      "1000 - 30\n",
      "20\n",
      "1000 - 1224\n",
      "2000 - 578\n",
      "21\n",
      "1000 - 993\n",
      "2000 - 668\n",
      "22\n",
      "1000 - 123\n",
      "23\n",
      "1000 - 227\n",
      "24\n",
      "1000 - 1558\n",
      "2000 - 574\n",
      "25\n",
      "1000 - 804\n",
      "2000 - 557\n",
      "26\n",
      "1000 - 1659\n",
      "2000 - 659\n",
      "27\n",
      "1000 - 1538\n",
      "2000 - 552\n",
      "28\n",
      "1000 - 257\n",
      "2000 - 353\n",
      "29\n",
      "1000 - 1971\n",
      "2000 - 971\n",
      "30\n",
      "1000 - 889\n",
      "2000 - 625\n",
      "31\n",
      "32\n",
      "1000 - 752\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1]\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "df = sp\n",
    "# final_k_list = [3, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1]\n",
    "print(final_k_list)\n",
    "xsum = 0\n",
    "for c in final_k_list:\n",
    "  xsum += c\n",
    "print(xsum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dim score 1: 0.7685023392370043\n",
      "dim score 2: 0.9168118143995935\n",
      "dim score 3: 0.9648055529089606\n",
      "3\n",
      "1\n",
      "dim score 1: 0.7685031946164731\n",
      "dim score 2: 0.9168109265552273\n",
      "dim score 3: 0.9648054823330969\n",
      "3\n",
      "2\n",
      "dim score 1: 0.7685043972291916\n",
      "dim score 2: 0.9168117155933843\n",
      "dim score 3: 0.9648052889552302\n",
      "3\n",
      "3\n",
      "dim score 1: 0.7685043619412597\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.9648043446501731\n",
      "3\n",
      "4\n",
      "dim score 1: 0.7684999269539811\n",
      "dim score 2: 0.916810442404802\n",
      "dim score 3: 0.9648052748400574\n",
      "3\n",
      "5\n",
      "dim score 1: 0.7685049166675488\n",
      "dim score 2: 0.9168115095118621\n",
      "dim score 3: 0.9648055529089606\n",
      "3\n",
      "6\n",
      "dim score 1: 0.7685058369768123\n",
      "dim score 2: 0.9168103534792137\n",
      "dim score 3: 0.9648042684282402\n",
      "3\n",
      "7\n",
      "dim score 1: 0.7685015177339501\n",
      "dim score 2: 0.9168103506561791\n",
      "dim score 3: 0.9648057533444138\n",
      "3\n",
      "8\n",
      "dim score 1: 0.7685012975372553\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.9648049120801178\n",
      "3\n",
      "9\n",
      "dim score 1: 0.768511097701697\n",
      "dim score 2: 0.9168105186267348\n",
      "dim score 3: 0.9648083815895802\n",
      "3\n",
      "10\n",
      "dim score 1: 0.7685049279596871\n",
      "dim score 2: 0.9168096434860242\n",
      "dim score 3: 0.9648055529089606\n",
      "3\n",
      "11\n",
      "dim score 1: 0.7685064326371025\n",
      "dim score 2: 0.9168114474051019\n",
      "dim score 3: 0.9648057067643436\n",
      "3\n",
      "12\n",
      "dim score 1: 0.768502219258036\n",
      "dim score 2: 0.9168096293708514\n",
      "dim score 3: 0.9648055246786151\n",
      "3\n",
      "13\n",
      "dim score 1: 0.7685030661684011\n",
      "dim score 2: 0.9168084324042021\n",
      "dim score 3: 0.9648037532244348\n",
      "3\n",
      "14\n",
      "dim score 1: 0.768504071168701\n",
      "dim score 2: 0.9168112427350971\n",
      "dim score 3: 0.964805293189782\n",
      "3\n",
      "15\n",
      "dim score 1: 0.7685004562729593\n",
      "dim score 2: 0.9168121418716013\n",
      "dim score 3: 0.9648052748400574\n",
      "3\n",
      "16\n",
      "dim score 1: 0.7684978760193801\n",
      "dim score 2: 0.9168119428476655\n",
      "dim score 3: 0.9648071817998962\n",
      "3\n",
      "17\n",
      "dim score 1: 0.7685011747352524\n",
      "dim score 2: 0.9168138385153661\n",
      "dim score 3: 0.9648047554017002\n",
      "3\n",
      "18\n",
      "dim score 1: 0.7685030661684011\n",
      "dim score 2: 0.9168093527134655\n",
      "dim score 3: 0.9648072100302417\n",
      "3\n",
      "19\n",
      "dim score 1: 0.7685013921089127\n",
      "dim score 2: 0.9168120543575302\n",
      "dim score 3: 0.9648073314207274\n",
      "3\n",
      "20\n",
      "dim score 1: 0.768506865972906\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.9648029486595879\n",
      "3\n",
      "21\n",
      "dim score 1: 0.7685010335835247\n",
      "dim score 2: 0.9168121418716013\n",
      "dim score 3: 0.9648051492150199\n",
      "3\n",
      "22\n",
      "dim score 1: 0.7685034105786163\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.9648056714764118\n",
      "3\n",
      "23\n",
      "dim score 1: 0.768499490795143\n",
      "dim score 2: 0.9168098001644418\n",
      "dim score 3: 0.964806590374158\n",
      "3\n",
      "24\n",
      "dim score 1: 0.7685017125233342\n",
      "dim score 2: 0.9168081585698507\n",
      "dim score 3: 0.964803667121881\n",
      "3\n",
      "25\n",
      "dim score 1: 0.768504137510013\n",
      "dim score 2: 0.9168144962824164\n",
      "dim score 3: 0.9648056714764118\n",
      "3\n",
      "26\n",
      "dim score 1: 0.768508979014267\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.964806190914769\n",
      "3\n",
      "27\n",
      "dim score 1: 0.768504137510013\n",
      "dim score 2: 0.9168092581418081\n",
      "dim score 3: 0.9648117635849716\n",
      "3\n",
      "28\n",
      "dim score 1: 0.7685051298066574\n",
      "dim score 2: 0.9168114008250319\n",
      "dim score 3: 0.9648043220658967\n",
      "3\n",
      "29\n",
      "dim score 1: 0.7685031946164731\n",
      "dim score 2: 0.9168125187467138\n",
      "dim score 3: 0.9648056714764118\n",
      "3\n",
      "30\n",
      "dim score 1: 0.7685085696742571\n",
      "dim score 2: 0.9168081472777125\n",
      "dim score 3: 0.9648044942710042\n",
      "3\n",
      "31\n",
      "dim score 1: 0.7685059075526761\n",
      "dim score 2: 0.9168101840971407\n",
      "dim score 3: 0.9648039296640942\n",
      "3\n",
      "32\n",
      "dim score 1: 0.7685145813263322\n",
      "dim score 2: 0.9168117777001443\n",
      "dim score 3: 0.964808191034748\n",
      "3\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def most_common_dimension(data, n_neighbors=5):\n",
    "  ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  total = len(ID)\n",
    "  # n_manifolds = max(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  return dimension,counter[dimension]/total\n",
    "def estimate_intrinsic_dimension(data,n_neighbors=5, method='most_common'):\n",
    "  res = 0\n",
    "  if method=='most_common':\n",
    "    return most_common_dimension(data,n_neighbors)[0]\n",
    "  if method=='average':\n",
    "    return np.around(np.mean(get_local_intrinsic_dimension(data),axis=0),0).astype(int)\n",
    "\n",
    "plt.close('all')\n",
    "D = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  X = df[df['manifold'] == 0][[j for j in range(d)]]\n",
    "  dim1 = get_dim(X, print_scores=True)\n",
    "  if dim1 < 6:\n",
    "    D.append(dim1)\n",
    "  else:\n",
    "    D.append(estimate_intrinsic_dimension(X, n_neighbors=2 * d))\n",
    "  print(D[-1])\n",
    "print(D)\n",
    "# [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Joining the cluster labeling\n",
    "def join_clusters():\n",
    "  df['cluster'] = [0]*n\n",
    "  data_index = [0] * (int(df.manifold.max()) + 1)\n",
    "  for i in range(n):\n",
    "    index_manifold = int(df.at[i,'manifold'])\n",
    "    if index_manifold!=-1:\n",
    "      df.at[i,'cluster'] = list_labels[index_manifold][data_index[index_manifold]]\n",
    "      data_index[index_manifold]+=1\n",
    "\n",
    "list_labels = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  if final_k_list[i] == 1:\n",
    "    list_labels.append([0] * len(df[df['manifold'] == i]))\n",
    "    continue\n",
    "  labels = get_cluster(df[df['manifold'] == i][[i for i in range(d)]], num_cluster=final_k_list[i], cluster_type=cluster_type[i])\n",
    "  list_labels.append(labels)\n",
    "print('------')\n",
    "print(int(df.manifold.max()) + 1)\n",
    "print('-------')\n",
    "join_clusters()"
   ],
   "metadata": {
    "id": "32ShiHNZ7GAO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "1000 - 1292\n",
      "2000 - 296\n",
      "3\n",
      "4\n",
      "5\n",
      "1000 - 448\n",
      "6\n",
      "7\n",
      "8\n",
      "1000 - 177\n",
      "1000 - 580\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1000 - 1331\n",
      "2000 - 335\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "1000 - 30\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "1000 - 1538\n",
      "2000 - 552\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "------\n",
      "33\n",
      "-------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output"
   ],
   "metadata": {
    "id": "n7PA_sYNakqD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import miniball\n",
    "\n",
    "THRESHOLD = 0.99\n",
    "def findNormalVectors(eigens,vectors):\n",
    "  res = sum(eigens)\n",
    "  current = 0\n",
    "  normal_vectors = []\n",
    "  for i in range(0,len(eigens)):\n",
    "    current += eigens[i]\n",
    "    if current/res > THRESHOLD:\n",
    "      for j in range(i+1,len(eigens)):\n",
    "        normal_vectors.append(vectors[j])\n",
    "      break\n",
    "  return normal_vectors\n",
    "# Outputting\n",
    "def get_affine_space(points):\n",
    "  X = points\n",
    "  s, v = get_pca(X)\n",
    "  #Finding Normal Vectors using PCA\n",
    "  A = findNormalVectors(s, v)\n",
    "  #Finding b-s using PCA\n",
    "  b = []\n",
    "  mean = np.mean(points, axis = 0)\n",
    "  for j in range(len(A)):\n",
    "    b.append(np.dot(A[j],mean))\n",
    "  return A, b\n",
    "def getOptimalBall(points):\n",
    "  points = np.asarray(points)\n",
    "  minlist = [min(points, key=lambda p: p[j])[j] for j in range(0,d)]\n",
    "  points = [[p[j]-minlist[j] for j in range(0,d)] for p in points]\n",
    "  mb = miniball.Miniball(points)\n",
    "  c = mb.center()\n",
    "  for j in range(0,d):\n",
    "    c[j]+=minlist[j]\n",
    "  r = math.sqrt(mb.squared_radius())\n",
    "  if not mb.is_valid():\n",
    "    print('Possibly invalid!')\n",
    "  print('Relative error', mb.relative_error())\n",
    "  return c,r\n",
    "def spherical_measure(data):\n",
    "  X = np.array(data)\n",
    "  n = len(X)\n",
    "  d = len(X[0])\n",
    "  c,r = getOptimalBall(X)\n",
    "  c = np.array(c)\n",
    "  r = np.array(r)\n",
    "  SSE = np.array([(np.linalg.norm(X[i]-c)-r)**2 for i in range(n)]).sum()\n",
    "  total = n * (r**2)\n",
    "  print(SSE / total)\n",
    "  return SSE/total\n",
    "def get_manifold_type(data, acceptable_error=1e-3):\n",
    "  X = data.to_numpy()\n",
    "  mcl_d = estimate_intrinsic_dimension(X,d)\n",
    "  pca_d = d-len(findNormalVectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "  if spherical_measure(data) < acceptable_error:\n",
    "    print(f'{pca_d} - {mcl_d}')\n",
    "    return 'Sphere'\n",
    "  if pca_d > mcl_d:\n",
    "    return 'Complex'\n",
    "  return 'Affine'\n",
    "\n",
    "vectors = [[[] for j in range(0,final_k_list[i])] for i in range(int(df.manifold.max()) + 1)]\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "outlier = []\n",
    "for i in range(n):\n",
    "  if int(df.at[i, 'manifold']) == -1:\n",
    "    outlier.append(i + 1)\n",
    "  else:\n",
    "    vectors[int(df.at[i, 'manifold'])][int(df.at[i, 'cluster'])].append(i + 1)\n",
    "\n",
    "with open('./output.txt', 'w') as f:\n",
    "  print(f'{n} {int(df.manifold.max()) + 1}', file=f)\n",
    "  for i in range(int(df.manifold.max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[j for j in range(d)]]\n",
    "    manifold_type = get_manifold_type(X)\n",
    "    if manifold_type == 'Complex':\n",
    "      dimension = D[i]\n",
    "    else:\n",
    "      dimension = d - len(findNormalVectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "    print(f'{dimension} ' + str(final_k_list[i]) + f' {manifold_type}', file=f)\n",
    "    if manifold_type != 'Complex':\n",
    "      A, B = get_affine_space(X)\n",
    "      for j in range(len(A)):\n",
    "        print(' '.join(list(map(str,A[j]))), file=f)\n",
    "      print(' '.join(list(map(str,B))), file=f)\n",
    "    if manifold_type == 'Sphere':\n",
    "      c, r = getOptimalBall(X)\n",
    "      print(' '.join(list(map(str, c))) + ' ' + str(r), file=f)\n",
    "    for j in range(0,final_k_list[i]):\n",
    "      print(str(len(vectors[i][j])) + ' ' + ' '.join(list(map(str, vectors[i][j]))), file=f)\n",
    "  print(str(len(outlier)) + ' ' + ' '.join(list(map(str, outlier))), file=f)\n",
    "\n"
   ],
   "metadata": {
    "id": "Y7Tl2J8nFRcI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Relative error 1.2738133750155331e-15\n",
      "0.05346663533637061\n",
      "1\n",
      "Relative error 6.666985422614167e-16\n",
      "0.034079719671682177\n",
      "2\n",
      "Relative error 1.03761843468402e-15\n",
      "2.5575119589249207e-05\n",
      "13 - 6\n",
      "Relative error 1.03761843468402e-15\n",
      "3\n",
      "Relative error 6.316160927560199e-16\n",
      "0.04880373694049591\n",
      "4\n",
      "Relative error 1.1719151611463616e-15\n",
      "0.021874941103887793\n",
      "5\n",
      "Relative error 6.296894741958706e-16\n",
      "0.03458981978942263\n",
      "6\n",
      "Relative error 3.454701099836993e-16\n",
      "0.04286437873208099\n",
      "7\n",
      "Relative error 5.595938050350367e-16\n",
      "0.33025432299086455\n",
      "8\n",
      "Relative error 2.995932069539125e-16\n",
      "0.1744886035236026\n",
      "9\n",
      "Relative error 7.805645178901585e-16\n",
      "0.018721001164110233\n",
      "10\n",
      "Relative error 1.005452992451539e-15\n",
      "0.031364227539769106\n",
      "11\n",
      "Relative error 7.680267836041271e-16\n",
      "0.03409101625516323\n",
      "12\n",
      "Relative error 1.0718549242307896e-15\n",
      "4.743205008037209e-05\n",
      "17 - 6\n",
      "Relative error 1.0718549242307896e-15\n",
      "13\n",
      "Relative error 2.013139461421669e-15\n",
      "5.251905064894631e-05\n",
      "17 - 6\n",
      "Relative error 2.013139461421669e-15\n",
      "14\n",
      "Relative error 8.86425295841806e-16\n",
      "0.044895786756694395\n",
      "15\n",
      "Relative error 1.1523911356691581e-15\n",
      "3.820428718605858e-05\n",
      "17 - 6\n",
      "Relative error 1.1523911356691581e-15\n",
      "16\n",
      "Relative error 3.4052666160764197e-16\n",
      "0.032842868070776125\n",
      "17\n",
      "Relative error 5.027531083144999e-16\n",
      "0.06431809546216957\n",
      "18\n",
      "Relative error 6.796258888719289e-16\n",
      "0.014609767795479931\n",
      "19\n",
      "Relative error 9.154450344862342e-16\n",
      "0.2173238380277979\n",
      "20\n",
      "Relative error 7.669131116165341e-16\n",
      "0.04762057758911102\n",
      "21\n",
      "Relative error 1.0920275709553906e-15\n",
      "0.017745954686834767\n",
      "22\n",
      "Relative error 7.989333263965695e-16\n",
      "0.0647879278243592\n",
      "23\n",
      "Relative error 2.151579928321559e-15\n",
      "0.07306217173770449\n",
      "24\n",
      "Relative error 1.290515437416228e-15\n",
      "7.660556983786495e-05\n",
      "17 - 6\n",
      "Relative error 1.290515437416228e-15\n",
      "25\n",
      "Relative error 6.604742005258601e-16\n",
      "0.3264712750715683\n",
      "26\n",
      "Relative error 1.913506452424828e-16\n",
      "0.3298236168893635\n",
      "27\n",
      "Relative error 1.9710417936463287e-15\n",
      "4.503936649422801e-05\n",
      "17 - 6\n",
      "Relative error 1.9710417936463287e-15\n",
      "28\n",
      "Relative error 1.1758643569185136e-15\n",
      "0.3264387812821005\n",
      "29\n",
      "Relative error 6.942903126060772e-16\n",
      "0.32781467967125383\n",
      "30\n",
      "Relative error 1.1379273523801016e-15\n",
      "0.021078495698637758\n",
      "31\n",
      "Relative error 3.833486707441405e-16\n",
      "0.08236314958364291\n",
      "32\n",
      "Relative error 6.873053664138317e-16\n",
      "0.07715730879830399\n"
     ]
    }
   ]
  }
 ]
}