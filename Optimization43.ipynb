{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "OptimizationA.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "qw9heMTlnccf",
    "BIfVETB9X19k",
    "KIB_rl2kX7W0",
    "2qV89xYLYDWu",
    "0t87F114Yi-L",
    "Nb_Nf5VVayMG",
    "hccGGCAcZ8D8"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn import preprocessing  # to normalise existing X\n",
    "import random\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import mixture\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import LocallyLinearEmbedding, trustworthiness\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "id": "jCjb0Crx7hKU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "id": "2qV89xYLYDWu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.sparse import csgraph, csc_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import scipy.sparse.linalg as LA\n",
    "import collections\n",
    "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
    "import scipy\n",
    "\n",
    "\n",
    "def mds_reduction(data, target_dimension):\n",
    "  return pd.DataFrame(MDS(n_components=target_dimension,eps=1e-4,n_init=15).fit_transform(data))\n",
    "#PCA get principal components Functions\n",
    "def get_pca(x):\n",
    "    pca = PCA(n_components = d)\n",
    "    pca.fit_transform(x)\n",
    "    # print(pca.explained_variance_ratio_)\n",
    "    return pca.explained_variance_ratio_, pca.components_\n",
    "#Identifying Components with small Eigenvalue\n",
    "THRESHOLD = 0.99\n",
    "def find_normal_vectors(eigens, vectors):\n",
    "  res = sum(eigens)\n",
    "  current = 0\n",
    "  normal_vectors = []\n",
    "  for i in range(0,len(eigens)):\n",
    "    current += eigens[i]\n",
    "    if current/res > THRESHOLD:\n",
    "      for j in range(i+1,len(eigens)):\n",
    "        normal_vectors.append(vectors[j])\n",
    "      break\n",
    "  return normal_vectors\n",
    "def normalized(X, c):\n",
    "  for i in range(len(X)):\n",
    "    X.iloc[i]-= c\n",
    "  return preprocessing.normalize(X)\n",
    "def variance(data):\n",
    "  mean = sum(data) / len(data)\n",
    "  deviations = [(x - mean) ** 2 for x in data]\n",
    "  variance = sum(deviations) / len(data)\n",
    "  return variance\n",
    "def get_reduced(X, target_dimension, reduction_type):\n",
    "  X_transformed = []\n",
    "  if reduction_type == 'iso':\n",
    "    embedding = Isomap(n_components=target_dimension, n_neighbors=10)\n",
    "    X_transformed = embedding.fit_transform(X)\n",
    "  elif reduction_type == 'pca':\n",
    "    transformer = PCA(n_components=target_dimension)\n",
    "    X_transformed = transformer.fit_transform(X)\n",
    "  elif reduction_type == 'k-pca':\n",
    "    transformer = KernelPCA(n_components=target_dimension, kernel='rbf')\n",
    "    X_transformed = transformer.fit_transform(X)\n",
    "  elif reduction_type == 'tsne':\n",
    "    X_transformed = TSNE(n_components=target_dimension, learning_rate='auto', init='pca').fit_transform(X)\n",
    "  elif reduction_type == 'mds':\n",
    "    X_transformed = mds_reduction(X,target_dimension)\n",
    "  elif reduction_type == 'LLE':\n",
    "    X_transformed = LocallyLinearEmbedding(n_components=target_dimension, n_neighbors=30).fit_transform(X)\n",
    "  return X_transformed\n",
    "def get_cluster(X, num_cluster, cluster_type):\n",
    "  if cluster_type == 'GMM':\n",
    "    model = mixture.GaussianMixture(n_components=num_cluster, covariance_type='full', n_init=100)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'k-means':\n",
    "    model=KMeans(n_clusters=num_cluster, n_init=10, max_iter=10000)\n",
    "    model.fit(X)\n",
    "    labels = model.predict(X)\n",
    "  elif cluster_type == 'HS':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster, linkage='single')\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'H':\n",
    "    model = AgglomerativeClustering(n_clusters=num_cluster)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'spectral':\n",
    "    model = SpectralClustering(assign_labels='discretize', n_clusters=num_cluster, random_state=77, n_init=1)\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "  elif cluster_type == 'custom-scan':\n",
    "    td = get_dim(X)\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "      n_components=td,\n",
    "      n_neighbors=d // 2,\n",
    "      max_iter=100000\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(td)])\n",
    "    # visualize_4d(res)\n",
    "    compo = ComponentScan(n_neighbor=50, step=50).fit(res)\n",
    "    compo.predict()\n",
    "    return compo.components_\n",
    "  elif cluster_type == 'PCAH':\n",
    "    tmp = pd.DataFrame(PCA(\n",
    "      n_components=3,\n",
    "    ).fit_transform(\n",
    "      X\n",
    "    ), columns=[i for i in range(3)])\n",
    "    return get_cluster(tmp, num_cluster, 'GMM')\n",
    "  elif cluster_type == 'custom':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom3d':\n",
    "    td = 3\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  elif cluster_type == 'custom50':\n",
    "    td = 2\n",
    "    p = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=2 * d).fit_transform(StandardScaler().fit_transform(X)), columns=[j for j in range(td)])\n",
    "    return get_cluster(p, cluster_type='GMM', num_cluster=num_cluster)\n",
    "  return labels\n",
    "def show_distance_graph(X):\n",
    "  neigh = NearestNeighbors(n_neighbors=2)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors(X)\n",
    "  # Plotting K-distance Graph\n",
    "  distances = np.sort(distances, axis=0)\n",
    "  distances = distances[:,1]\n",
    "  print(distances[-700:])\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.plot(distances)\n",
    "  plt.title('K-distance Graph',fontsize=20)\n",
    "  plt.xlabel('Data Points sorted by distance',fontsize=14)\n",
    "  plt.ylabel('Epsilon',fontsize=14)\n",
    "  plt.show()\n",
    "  #Visualization in 4D\n",
    "def visualize_4d(frame, hot=True):\n",
    "  fig = plt.figure(figsize=(7, 7))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "  x = np.array(frame.iloc[:,0])\n",
    "  if len(frame.columns) > 1:\n",
    "    y = np.array(frame.iloc[:,1])\n",
    "  if len(frame.columns) > 2:\n",
    "    z = np.array(frame.iloc[:,2])\n",
    "  if len(frame.columns) == 1:\n",
    "    img = ax.scatter(x, x, s=2)\n",
    "  if len(frame.columns) == 2:\n",
    "    img = ax.scatter(x, y, s=2)\n",
    "  elif len(frame.columns) == 3:\n",
    "    img = ax.scatter(x, y, z, s=2)\n",
    "  else:\n",
    "    c = np.array(frame.iloc[:,3])\n",
    "    if hot:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap=plt.hot(), s=2)\n",
    "    else:\n",
    "      img = ax.scatter(x, y, z, c=c, cmap='viridis', s=2)\n",
    "  plt.show()\n",
    "def merge(X, col, val_list):\n",
    "  def get_col(row):\n",
    "    for ind in range(len(val_list)):\n",
    "      if row[col] in val_list[ind]:\n",
    "        return 100 + ind\n",
    "    return row[col]\n",
    "  X[col] = X.apply(get_col, axis=1)\n",
    "  X[col] = LabelEncoder().fit_transform(X[col])\n",
    "  X[col] -= 1\n",
    "  return X\n",
    "def get_local_intrinsic_dimension(data, n_neighbors=5):\n",
    "  X = np.array(data)\n",
    "  M = np.matrix(X)\n",
    "  L = n_neighbors\n",
    "  if not isinstance(L, (int, np.integer))  or L<0:\n",
    "    return 'n_neighbors must be a positive integer!'\n",
    "  neigh = NearestNeighbors(n_neighbors=L)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors()\n",
    "  mean = [np.mean([M[indices[i][j]] for j in range(L)],axis=0) for i in range(len(X))]\n",
    "  #Calculating the local covariance matrix for each point\n",
    "  C = [1/L * sum([np.dot( (M[indices[i][j],:]-mean[i]).transpose() , (M[indices[i][j],:]-mean[i]) ) for j in range(L)]) for i in range(len(X))]\n",
    "\n",
    "  #Intrinsic Dimension Estimation\n",
    "  THRESHOLD = 0.05\n",
    "  intrinsic_dimension = [0] * len(X)\n",
    "\n",
    "  E = [sorted(LA.eigsh(C[i])[0], reverse=True) for i in range(len(X))]\n",
    "  for i in range(len(X)):\n",
    "    eigen_list = E[i]\n",
    "    d = len(eigen_list)\n",
    "    first_eigenvalue= eigen_list[0]\n",
    "    for j in range(1,d):\n",
    "      if eigen_list[j]/first_eigenvalue < THRESHOLD:\n",
    "        intrinsic_dimension[i]=j\n",
    "        break\n",
    "    if intrinsic_dimension[i]==0:\n",
    "      intrinsic_dimension[i]=d\n",
    "  return np.array(intrinsic_dimension)\n",
    "def is_manifold(data, n_neighbors=5, error=0.05, is_calculated=False):\n",
    "  #Assuming data is consisted of submanifolds with DIFFERENT dimensions OR is just consisted of one manifold\n",
    "  if not is_calculated:\n",
    "    ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  else:\n",
    "    ID = data['local_dim'].to_numpy()\n",
    "  total = len(ID)\n",
    "  # n_manifolds = max(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  print(counter)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  accuracy = counter[dimension]/total\n",
    "  if accuracy > 1-error:\n",
    "    # print(f'Accuracy: {accuracy}. Data resides on a {dimension}-dimensional manifold!')\n",
    "    return True,accuracy\n",
    "  # print(f'Accuracy: {accuracy} -> Inconclusive!')\n",
    "  return False,accuracy\n",
    "def predict_n_clusters(data, method='eigengap', n_neighbors=5, plot=False):\n",
    "  if method=='eigengap':\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(data)\n",
    "    distances, neighbors = nbrs.kneighbors(data)\n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for i in range(len(data)):\n",
    "      for j in neighbors[i]:\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "        val.append(1)\n",
    "    mat = csc_matrix((np.array(val), (np.array(row), np.array(col))), shape=(len(data), len(data)))\n",
    "    k, _, _ = eigengap_heuristic(mat, plot=plot)\n",
    "    return k\n",
    "  return 'Invalid Combination of algorithm and method'\n",
    "def showSilouette(X, model_list, plot=True):\n",
    "  silouette = [silhouette_score(X, model_list[i].fit_predict(X)) for i in range(len(model_list))]\n",
    "  if plot:\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.plot(range(2, len(model_list)+2),silouette,'gs-')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette Curve')\n",
    "    plt.show()\n",
    "  return silouette.index(max(silouette))+2\n",
    "def getAffinityMatrix(coordinates, n_neighbors):\n",
    "  A = kneighbors_graph(coordinates, n_neighbors=n_neighbors, mode='connectivity', include_self=False).toarray()\n",
    "  for i in range(len(A)):\n",
    "    for j in range(len(A[0])):\n",
    "      if A[i][j] == 1:\n",
    "        A[j][i] = 1\n",
    "  return A\n",
    "def eigengap_heuristic(A, plot = True):\n",
    "    L = csgraph.laplacian(A, normed=True)\n",
    "    # print(L)\n",
    "    # n_components = A.shape[0]\n",
    "    # LM parameter : Eigenvalues with largest magnitude (eigs, eigsh), that is, largest eigenvalues in\n",
    "    # the euclidean norm of complex numbers.\n",
    "    eigenvalues = scipy.linalg.eigh(L, eigvals_only=True)\n",
    "    print(eigenvalues[:10])\n",
    "    # eigenvalues = np.negative(eigenvalues[::-1])\n",
    "    # eigenvalues, eigenvectors = LA.einp.negative(L)g(L)\n",
    "    if plot:\n",
    "        plt.title('Largest eigen values of input matrix')\n",
    "        plt.scatter(np.arange(len(eigenvalues))[:10], eigenvalues[:10])\n",
    "        plt.grid()\n",
    "\n",
    "    # Identify the optimal number of clusters as the index corresponding\n",
    "    # to the larger gap between eigen values\n",
    "    max_gap = 0\n",
    "    gap_pre_index = 0\n",
    "    for i in range(1, 6):\n",
    "        gap = np.abs(eigenvalues[i] / eigenvalues[i - 1])\n",
    "        if gap > max_gap:\n",
    "            max_gap = gap\n",
    "            gap_pre_index = i\n",
    "\n",
    "    return gap_pre_index\n",
    "def predict_n_clusters(data, plot=False, **kwargs):\n",
    "  return eigengap_heuristic(getAffinityMatrix(data, n_neighbors=15), plot)\n",
    "class ComponentScan:\n",
    "\n",
    "  def __init__(self, n_neighbor=50, step=50):\n",
    "    self.neighbors = None\n",
    "    self.points = None\n",
    "    self.n_neighbor = n_neighbor\n",
    "    self.step = step\n",
    "    self.components_ = None\n",
    "\n",
    "  def fit(self, X):\n",
    "    self.neighbors = []\n",
    "    for i in range(5):\n",
    "      nbrs = NearestNeighbors(n_neighbors=self.n_neighbor + i * self.step, algorithm='brute').fit(X)\n",
    "      self.neighbors.append(nbrs.kneighbors(X)[1])\n",
    "    self.points = X.to_numpy()\n",
    "    self.components_ = np.full((len(X)), -1)\n",
    "    return self\n",
    "\n",
    "  def predict(self):\n",
    "    cnt = 0\n",
    "    ind = 0\n",
    "    c = -1\n",
    "    rep = 0\n",
    "    while True:\n",
    "      while ind < len(self.points):\n",
    "        if self.components_[ind] == -1:\n",
    "          break\n",
    "        ind += 1\n",
    "      if ind == len(self.points):\n",
    "        break\n",
    "      stack = [ind]\n",
    "      combo = []\n",
    "      cnt = 0\n",
    "      c += 1\n",
    "      while len(stack) > 0:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "          print(f'{cnt} - {len(stack)}')\n",
    "        v = stack.pop()\n",
    "        self.components_[v] = c\n",
    "        for u in self.neighbors[rep][v]:\n",
    "          if self.components_[u] == -1:\n",
    "            stack.append(u)\n",
    "            combo.append(u)\n",
    "            self.components_[u] = c\n",
    "      if len(combo) < 100:\n",
    "        rep += 1\n",
    "        if rep == 5:\n",
    "          rep = 0\n",
    "        for c in combo:\n",
    "          self.components_[c] = -1\n",
    "      else:\n",
    "        rep = 0\n",
    "    return c + 1\n",
    "def get_dim(X, threshold=0.95, print_scores=False):\n",
    "  for td in range(1, 15):\n",
    "    res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=50, max_iter=10000).fit_transform(X),\n",
    "                       columns=[i for i in range(td)])\n",
    "    score = trustworthiness(X, res, n_neighbors=d)\n",
    "    if print_scores:\n",
    "      print(f'dim score {td}: {score}')\n",
    "    if score >= threshold:\n",
    "      return td\n",
    "  return d"
   ],
   "metadata": {
    "id": "lreiVAqgbFK7",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open Input"
   ],
   "metadata": {
    "id": "E59D74nTYeiL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Input\n",
    "file = open('./R43.txt','r')\n",
    "d,n,m,k,p = list(file.readline().split())\n",
    "d,n,p,k = map(int, [d, n, p, k])\n",
    "k_list = list(map(int,file.readline().split()))\n",
    "ar=[]\n",
    "for i in range(0,n):\n",
    "  ar.append(list(map(float,file.readline().split())))\n",
    "df= pd.DataFrame(ar)\n",
    "df.describe()"
   ],
   "metadata": {
    "id": "lU5fWrUlu-e1",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(df[[i for i in range(d)]])\n",
    "distances, indices = nbrs.kneighbors(df)\n",
    "out = 0\n",
    "for i in range(n):\n",
    "  if distances[i][1] > 100:\n",
    "    df.at[i, 'manifold'] = -1\n",
    "    out += 1\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Submanifolds"
   ],
   "metadata": {
    "id": "YdIkC1Nkll0g",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_best_eps(min_sample):\n",
    "  tmp = df[df['manifold'] != -1].copy()\n",
    "  l, r = 0, 80\n",
    "  while (r - l) > 1:\n",
    "    mid = (r + l) / 2\n",
    "    print(mid)\n",
    "    model_name = 'dbscan'\n",
    "    model = DBSCAN(eps=mid, min_samples=min_sample)\n",
    "    model.fit(tmp[[i for i in range(d)]])\n",
    "    tmp['subset'] = model.labels_\n",
    "    print(f\"count: {len(tmp[tmp['subset'] == -1])}\")\n",
    "    print(f\"cluster count: {tmp['subset'].max() + 1}\")\n",
    "    if len(tmp[tmp['subset'] == -1]) > 0:\n",
    "      l = mid\n",
    "    else:\n",
    "      r = mid\n",
    "  return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#DBSCAN\n",
    "# best_eps = find_best_eps(5)\n",
    "best_eps = 49.375\n",
    "model = DBSCAN(eps=best_eps, min_samples=5)\n",
    "model.fit(df[df['manifold'] != -1][[i for i in range(d)]])\n",
    "df.loc[df['manifold'] != -1, 'manifold'] = model.labels_"
   ],
   "metadata": {
    "id": "WLrq5pnTl_Kp",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# multi = [0, 1, 4, 5, 14, 20, 32]\n",
    "multi = []\n",
    "if multi is None:\n",
    "  multi = []\n",
    "  for i in range(int(df['manifold'].max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[i for i in range(d)]]\n",
    "    if not is_manifold(X, n_neighbors=d // 2)[0] and not is_manifold(X, n_neighbors=3 * d // 2)[0]:\n",
    "      multi.append(i)\n",
    "      td = 3\n",
    "      res = pd.DataFrame(LocallyLinearEmbedding(n_components=td, n_neighbors=20, max_iter=10000).fit_transform(X),\n",
    "                           columns=[i for i in range(td)])\n",
    "      visualize_4d(res)\n",
    "      visualize_4d(X)\n",
    "\n",
    "\n",
    "print(multi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sp = df.copy()\n",
    "# range(int(df.manifold.max()) + 1)\n",
    "for subset in multi:\n",
    "  print(f'processing subset {subset}')\n",
    "  tmp = df[df['manifold'] == subset][[i for i in range(d)]]\n",
    "  td = get_dim(tmp) or 6\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=d // 2,\n",
    "    max_iter=100000\n",
    "  ).fit_transform(\n",
    "    tmp\n",
    "  ), columns=[i for i in range(td)])\n",
    "  # visualize_4d(res)\n",
    "  k = ComponentScan(n_neighbor=50, step=50).fit(res).predict()\n",
    "  print(f'manifold count: {k}')\n",
    "  if k > 10:\n",
    "    continue\n",
    "  sp.loc[sp['manifold'] == subset, 'sub1'] = get_cluster(res, k, 'H')\n",
    "  print(sp.loc[sp['manifold'] == subset, 'sub1'].value_counts())\n",
    "  visualize_4d(pd.DataFrame(get_reduced(tmp, 3, 'pca'), columns=[j for j in range(3)]), hot=False)\n",
    "if len(multi) > 0:\n",
    "  sp['manifold'] = sp.manifold.astype(str) + '-' + sp.sub1.astype(str)\n",
    "  sp = sp.drop(['sub1'], axis=1)\n",
    "  sp['manifold'] = LabelEncoder().fit_transform(sp['manifold'])\n",
    "  sp['manifold'] -= 1\n",
    "  sp['manifold'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# custom cluster for manifold\n",
    "final_k_list = []\n",
    "cluster_type = []\n",
    "for i in range(int(sp.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  if i in [0, 6, 14]:\n",
    "    cluster_type.append('PCAH')\n",
    "    final_k_list.append(3)\n",
    "    continue\n",
    "  X = sp[sp['manifold'] == i][[j for j in range(d)]]\n",
    "  td = get_dim(X) or 6\n",
    "  res = pd.DataFrame(LocallyLinearEmbedding(\n",
    "    n_components=td,\n",
    "    n_neighbors=d // 2,\n",
    "    max_iter=100000\n",
    "  ).fit_transform(\n",
    "    X\n",
    "  ), columns=[i for i in range(td)])\n",
    "  k = ComponentScan(n_neighbor=50, step=50).fit(res).predict()\n",
    "  if k < 10:\n",
    "    cluster_type.append('custom-scan')\n",
    "  else:\n",
    "    cluster_type.append('HS')\n",
    "  final_k_list.append(k if k < 10 else 1)"
   ],
   "metadata": {
    "id": "Ft0MXRklKLuC",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "df = sp\n",
    "# final_k_list = [3, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1]\n",
    "print(final_k_list)\n",
    "xsum = 0\n",
    "for c in final_k_list:\n",
    "  xsum += c\n",
    "print(xsum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def most_common_dimension(data, n_neighbors=5):\n",
    "  ID = get_local_intrinsic_dimension(data, n_neighbors=n_neighbors)\n",
    "  total = len(ID)\n",
    "  # n_manifolds = max(ID)\n",
    "  counter = collections.Counter(ID)\n",
    "  dimension = counter.most_common(1)[0][0]\n",
    "  return dimension,counter[dimension]/total\n",
    "def estimate_intrinsic_dimension(data,n_neighbors=5, method='most_common'):\n",
    "  res = 0\n",
    "  if method=='most_common':\n",
    "    return most_common_dimension(data,n_neighbors)[0]\n",
    "  if method=='average':\n",
    "    return np.around(np.mean(get_local_intrinsic_dimension(data),axis=0),0).astype(int)\n",
    "\n",
    "plt.close('all')\n",
    "D = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  X = df[df['manifold'] == 0][[j for j in range(d)]]\n",
    "  dim1 = get_dim(X, print_scores=True)\n",
    "  if dim1 < 6:\n",
    "    D.append(dim1)\n",
    "  else:\n",
    "    D.append(estimate_intrinsic_dimension(X, n_neighbors=2 * d))\n",
    "  print(D[-1])\n",
    "print(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Joining the cluster labeling\n",
    "def join_clusters():\n",
    "  df['cluster'] = [0]*n\n",
    "  data_index = [0] * (int(df.manifold.max()) + 1)\n",
    "  for i in range(n):\n",
    "    index_manifold = int(df.at[i,'manifold'])\n",
    "    if index_manifold!=-1:\n",
    "      df.at[i,'cluster'] = list_labels[index_manifold][data_index[index_manifold]]\n",
    "      data_index[index_manifold]+=1\n",
    "\n",
    "list_labels = []\n",
    "for i in range(int(df.manifold.max()) + 1):\n",
    "  print(i)\n",
    "  if final_k_list[i] == 1:\n",
    "    list_labels.append([0] * len(df[df['manifold'] == i]))\n",
    "    continue\n",
    "  labels = get_cluster(df[df['manifold'] == i][[i for i in range(d)]], num_cluster=final_k_list[i], cluster_type=cluster_type[i])\n",
    "  list_labels.append(labels)\n",
    "print('------')\n",
    "print(int(df.manifold.max()) + 1)\n",
    "print('-------')\n",
    "join_clusters()"
   ],
   "metadata": {
    "id": "32ShiHNZ7GAO",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output"
   ],
   "metadata": {
    "id": "n7PA_sYNakqD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import miniball\n",
    "\n",
    "THRESHOLD = 0.99\n",
    "def findNormalVectors(eigens,vectors):\n",
    "  res = sum(eigens)\n",
    "  current = 0\n",
    "  normal_vectors = []\n",
    "  for i in range(0,len(eigens)):\n",
    "    current += eigens[i]\n",
    "    if current/res > THRESHOLD:\n",
    "      for j in range(i+1,len(eigens)):\n",
    "        normal_vectors.append(vectors[j])\n",
    "      break\n",
    "  return normal_vectors\n",
    "# Outputting\n",
    "def get_affine_space(points):\n",
    "  X = points\n",
    "  s, v = get_pca(X)\n",
    "  #Finding Normal Vectors using PCA\n",
    "  A = findNormalVectors(s, v)\n",
    "  #Finding b-s using PCA\n",
    "  b = []\n",
    "  mean = np.mean(points, axis = 0)\n",
    "  for j in range(len(A)):\n",
    "    b.append(np.dot(A[j],mean))\n",
    "  return A, b\n",
    "def getOptimalBall(points):\n",
    "  points = np.asarray(points)\n",
    "  minlist = [min(points, key=lambda p: p[j])[j] for j in range(0,d)]\n",
    "  points = [[p[j]-minlist[j] for j in range(0,d)] for p in points]\n",
    "  mb = miniball.Miniball(points)\n",
    "  c = mb.center()\n",
    "  for j in range(0,d):\n",
    "    c[j]+=minlist[j]\n",
    "  r = math.sqrt(mb.squared_radius())\n",
    "  if not mb.is_valid():\n",
    "    print('Possibly invalid!')\n",
    "  print('Relative error', mb.relative_error())\n",
    "  return c,r\n",
    "def spherical_measure(data):\n",
    "  X = np.array(data)\n",
    "  n = len(X)\n",
    "  d = len(X[0])\n",
    "  c,r = getOptimalBall(X)\n",
    "  c = np.array(c)\n",
    "  r = np.array(r)\n",
    "  SSE = np.array([(np.linalg.norm(X[i]-c)-r)**2 for i in range(n)]).sum()\n",
    "  total = n * (r**2)\n",
    "  print(SSE / total)\n",
    "  return SSE/total\n",
    "def get_manifold_type(data, acceptable_error=1e-3):\n",
    "  X = data.to_numpy()\n",
    "  mcl_d = estimate_intrinsic_dimension(X,d)\n",
    "  pca_d = d-len(findNormalVectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "  if spherical_measure(data) < acceptable_error:\n",
    "    print(f'{pca_d} - {mcl_d}')\n",
    "    return 'Sphere'\n",
    "  if pca_d > mcl_d:\n",
    "    return 'Complex'\n",
    "  return 'Affine'\n",
    "\n",
    "vectors = [[[] for j in range(0,final_k_list[i])] for i in range(int(df.manifold.max()) + 1)]\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "outliar = []\n",
    "for i in range(n):\n",
    "  if int(df.at[i, 'manifold']) == -1:\n",
    "    outliar.append(i + 1)\n",
    "  else:\n",
    "    vectors[int(df.at[i, 'manifold'])][int(df.at[i, 'cluster'])].append(i + 1)\n",
    "\n",
    "with open('./output.txt', 'w') as f:\n",
    "  print(f'{n} {int(df.manifold.max()) + 1}', file=f)\n",
    "  for i in range(int(df.manifold.max()) + 1):\n",
    "    print(i)\n",
    "    X = df[df['manifold'] == i][[j for j in range(d)]]\n",
    "    manifold_type = get_manifold_type(X)\n",
    "    if manifold_type == 'Complex':\n",
    "      dimension = D[i]\n",
    "    else:\n",
    "      dimension = d - len(findNormalVectors(get_pca(X)[0], get_pca(X)[1]))\n",
    "    print(f'{dimension} ' + str(final_k_list[i]) + f' {manifold_type}', file=f)\n",
    "    if manifold_type != 'Complex':\n",
    "      A, B = get_affine_space(X)\n",
    "      for j in range(len(A)):\n",
    "        print(' '.join(list(map(str,A[j]))), file=f)\n",
    "      print(' '.join(list(map(str,B))), file=f)\n",
    "    if manifold_type == 'Sphere':\n",
    "      c, r = getOptimalBall(X)\n",
    "      print(' '.join(list(map(str, c))) + ' ' + str(r), file=f)\n",
    "    for j in range(0,final_k_list[i]):\n",
    "      print(str(len(vectors[i][j])) + ' ' + ' '.join(list(map(str, vectors[i][j]))), file=f)\n",
    "  print(str(len(outliar)) + ' ' + ' '.join(list(map(str, outliar))), file=f)\n",
    "\n"
   ],
   "metadata": {
    "id": "Y7Tl2J8nFRcI",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}